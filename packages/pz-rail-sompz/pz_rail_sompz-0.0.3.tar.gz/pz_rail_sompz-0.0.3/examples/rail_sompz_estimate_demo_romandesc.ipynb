{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a4d2c4-93f6-4124-8e94-688797d59729",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAIL SOMPZ Estimator Demo\n",
    "\n",
    "Authors: Sam Schmidt, Justin Myles\n",
    "\n",
    "Last successfully run: April 17th, 2025\n",
    "\n",
    "This demo notebook follows the informer demo for the `rail_sompz` method, `rail_sompz_inform_demo.ipynb`, and uses the model files `DEMO_romandesc_model_deep.pkl` and `DEMO_romandesc_model_wide.pkl` that are created in that notebook.  So, you will need to run that notebook and train those two model SOMs before you run this demo, which shows how to run the estimate stage and produce tomographic bin estimates.\n",
    "\n",
    "The algorithm works by determining weights for a spectroscopic dataset based on a wider \"deep\" dataset relative to a (usually larger) wide dataset.  See [Buchs, Davis et al. 2019](https://arxiv.org/abs/1901.05005), [Myles, Alarcon et al. 2021](https://arxiv.org/pdf/2012.08566) and references in [Campos et al. 2023](https://github.com/AndresaCampos/sompz_y6) for more details on the method.\n",
    "\n",
    "The full process entails multiple steps, a common one is identifying the \"best\" cell in a SOM that data from the spectroscopic, deep/balrog, and wide data belong to, but also computing weights for the mappings, before finally assembling the tomographic bin estimates.  This notebook will go through the multiple stages necessary to construct the final N(z) estimates.\n",
    "\n",
    "\n",
    "We'll start with our usual imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af1c10-6fce-4276-b86f-6fe57cf80ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from rail.core.utils import RAILDIR\n",
    "from rail.core import common_params\n",
    "import tables_io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import astropy.io.fits as fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031bd92-af09-42cc-9fef-d9665c3ad272",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_io.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296324b-29a4-4227-9532-b290e4a94cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from rail.estimation.algos.sompz import SOMPZInformer\n",
    "from rail.estimation.algos.sompz import SOMPZEstimatorWide, SOMPZEstimatorDeep\n",
    "from rail.estimation.algos.sompz import SOMPZPzc, SOMPZPzchat, SOMPZPc_chat\n",
    "from rail.estimation.algos.sompz import SOMPZTomobin, SOMPZnz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4597943c-fd10-4114-8160-ad4d590ca7e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "The SOMPZ method usually leverages a \"deep\" dataset with extra bands (often in the near-infrared), where the extra photometric information in the extended wavelength coverage enables a magnitudes/colors -> redshift mapping with less degeneracies than when using optical colors along.  For this demo, we will use data from the Rubin-Roman simulation [Citation needed!], which does contain simluated photometry for both the Rubin optical `ugrizy` bands as well as the Roman `JHFK` bands.  We have included a command-line tool in RAIL that will grab several data files that we will use in this demo.  If you ran the informer demo they are already in place and you can ignore the following cell, if you moved/deleted files, or just copied the model from the informer stage and still need the data, then uncomment the lines in the cell below to grab the data files, move, and untar them in the appropriate location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4dc6fe-719e-40e6-990a-9b0e832c8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -O https://portal.nersc.gov/cfs/lsst/PZ/roman_desc_demo_data.tar.gz\n",
    "# !mkdir DEMODATA\n",
    "# !tar -xzvf roman_desc_demo_data.tar.gz\n",
    "# !mv romandesc*.hdf5 DEMODATA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46b10b-8cca-41fd-9044-ac51ac9f6754",
   "metadata": {},
   "source": [
    "Now, let's load the three files that we will use into memory.  The \"spec\" file contains the galaxies with spectroscopic redshifts, these are usually a subset of the \"deep\" data (and that is the case here).  The \"deep\" data contains both optical and NIR bands, in this case `ugrizyJHF`.  And the \"wide\" data contains only `ugrizy` photometry.  The code will determine the cell occupation of the spec sample, determine weights via the deep sample, and attempt to create tomographic bin estimates for the sample based on SOM cell occupation.\n",
    "\n",
    "\n",
    "There are two sets of files included in the Rubin-Roman download, one set that is a factor of 20 larger than the other.  For a quick demo, use the file names for `specfile`, `deepfile`, and `widefile` as-is below, for a more robust estimate with more training and estimation data, switch to the larger files by uncommenting and commenting the file names below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231a13e-260f-4271-93ec-a893fb876268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf95e06-d6a6-4ac9-9260-c5271ed6f40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582c84a-eb2c-43df-bfcd-a92992d745b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "## Larger files to use if you want slightly more robust demo (will take longer to run)\n",
    "#specfile = \"./DEMODATA/romandesc_spec_data_37k_noinf.hdf5\"\n",
    "#deepfile = \"./DEMODATA/romandesc_deep_data_75k_noinf.hdf5\"\n",
    "#widefile = \"./DEMODATA/romandesc_wide_data_100k_noinf.hdf5\"\n",
    "## smaller files for a quick demo, swap which lines are commented if you don't mind some extra run time\n",
    "specfile = \"./DEMODATA/romandesc_spec_data_18c_noinf.hdf5\"\n",
    "deepfile = \"./DEMODATA/romandesc_deep_data_37c_noinf.hdf5\"\n",
    "widefile = \"./DEMODATA/romandesc_wide_data_50c_noinf.hdf5\"\n",
    "\n",
    "spec_data = DS.read_file(\"spec_data\", TableHandle, specfile)\n",
    "balrog_data = DS.read_file(\"deep_data\", TableHandle, deepfile)\n",
    "wide_data = DS.read_file(\"wide_data\", TableHandle, widefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7bcca-8e47-461a-81cc-cf07e6bb9293",
   "metadata": {},
   "source": [
    "We need to set up several parameters used by the estimate stages, namely the names of the inputs (for both deep and wide), the names of the input errors (again for both deep and wide), the zero points.  In our dataset, the bands are simply called e.g. `u`, and `J`, and the errors `u_err` and `J_err`.  The \"deep\" SOM we will use both optical and NIR bands, for the wide data we will only use ugrizy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fce31d-31b9-46d5-adff-e7c1056ec822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y','J','H', 'F']\n",
    "#bands = ['u','g','r','i','z','y']\n",
    "\n",
    "deepbands = []\n",
    "deeperrs = []\n",
    "zeropts = []\n",
    "widezeropts = []\n",
    "for band in bands:\n",
    "    deepbands.append(f'{band}')\n",
    "    deeperrs.append(f'{band}_err')\n",
    "    zeropts.append(30.)\n",
    "\n",
    "widebands = []\n",
    "wideerrs = []  \n",
    "for band in bands[:6]:\n",
    "    widebands.append(f'{band}')\n",
    "    wideerrs.append(f'{band}_err')\n",
    "    widezeropts.append(30.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a311fd5-7554-497c-965e-62136809fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(widebands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc7000-a2fa-4e17-99d9-2ec66bffdb9d",
   "metadata": {},
   "source": [
    "The full SOMPZ process involves multiple stages: in order to construct an N(z) estimate we must:\n",
    "1) Find the best cell mapping for all of the deep/balrog galaxies into the deep SOM using stage `SOMPZEstimatorDeep`\n",
    "2) Find the best cell mapping for all of the deep/balrog galaxies into the wide SOM using stage `SOMPZEstimatorWide`\n",
    "3) Find the best cell mapping for all of the spectrscopic galaxies into the deep SOM using stage `SOMPZEstimatorDeep`\n",
    "\n",
    "4) Use these cell assignments to compute the pz_c redshift histograms in deep SOM cells using stage `SOMPZPzc`. These distributions are redshift pdfs for individual deep SOM cells. \n",
    "5) Compute the 'transfer function' using stage `SOMPZPc_chat`. The 'transfer function' weights relating deep to wide photometry. These weights set the relative importance of p(z) from deep SOM cells for each corresponding wide SOM cell. These are traditionally made by injecting galaxies into images with Balrog.\n",
    "6) Find the best cell mapping for all of the wide-field galaxies into the wide SOM using stage `SOMPZEstimatorWide`\n",
    "7) Compute more weights using stage `SOMPZPzchat`. These weights represent the normalized occupation fraction of each wide SOM cell relative to the full sample.\n",
    "8) Find the best cell mapping for all of the spectroscopic galaxies into the wide SOM using stage `SOMPZEstimatorWide`\n",
    "9) Define a tomographic bin mapping using stage `SOMPZTomobin`\n",
    "10) Assemble the final tomographic bin estimates with stage `SOMPZnz`\n",
    "\n",
    "Note the repeated use of `SOMPZEstimatorDeep` and `SOMPZEstimatorWide` on multiple datasets.  We will have to be careful to define aliases so that `ceci` knows which datasets to use as inputs for these stages.\n",
    "\n",
    "We will begin with step 1) above, setting up a stage to compute the cell assignments for the deep/balrog data using the deep SOM, first, let's set up some common parameters that will be used for each of the deep and wide SOMs in dictionaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604e512-0cd9-49f3-b49a-8ac8df850e80",
   "metadata": {},
   "source": [
    "There are many configuration parameters that we can access to control the behavior of the estimate stage, these are described below.  Any values not specified will take on their default values as set in the parameter config that is located in the class:\n",
    "\n",
    "`hdf5_groupname`: hdf5_groupname for data<br>\n",
    "`redshift_col`: column name for true redshift in specz sample<br>\n",
    "`inputs`: list of the names of columns to be used as inputs for the data<br>\n",
    "`input_errs`: list of the names of columns containing errors on inputs for the data<br>\n",
    "`zero_points`: zero points for converting mags to fluxes for the data, if needed<br>\n",
    "`som_shape`: shape for the som, must be a 2-element list<br>\n",
    "`som_minerror`: floor placed on observational error on each feature in the som<br>\n",
    "`som_wrap`: flag to set whether the SOM has periodic boundary conditions<br>\n",
    "`som_take_log`: flag to set whether to take log of inputs (i.e. for fluxes) for the som<br>\n",
    "`convert_to_flux`: flag for whether to convert input columns to fluxes for the input data, set to true if inputs are mags and to False if inputs are already fluxes<br>\n",
    "`set_threshold`: flag for whether to replace values below a threshold with a set number<br>\n",
    "`thresh_val`: threshold value for set_threshold for the input data<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd126f-d458-404e-85e0-70ee104a4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_som_params = dict(inputs=deepbands, \n",
    "                       input_errs=deeperrs,\n",
    "                       hdf5_groupname=\"\",\n",
    "                       zero_points=zeropts,\n",
    "                       som_shape=[32,32], # now a list instead of a tuple!\n",
    "                       som_minerror=0.01,\n",
    "                       som_take_log=False,\n",
    "                       convert_to_flux=True,\n",
    "                       set_threshold=True,\n",
    "                       thresh_val=1.e-5,\n",
    "                       thresh_val_err=1.e-5)\n",
    "\n",
    "wide_som_params = dict(inputs=widebands, \n",
    "                       input_errs=wideerrs,\n",
    "                       hdf5_groupname=\"\",\n",
    "                       zero_points=widezeropts,\n",
    "                       som_shape=[25,25], # now a list instead of a tuple!\n",
    "                       som_minerror=0.005,\n",
    "                       som_take_log=False,\n",
    "                       convert_to_flux=True,\n",
    "                       set_threshold=True,\n",
    "                       thresh_val=1.e-5,\n",
    "                       thresh_val_err=1.e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde5b65-770b-4501-85b1-62b61b3bd681",
   "metadata": {},
   "source": [
    "Now, let's set up the first stage and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557bfbf1-2e90-4c1e-a7bd-7d6025aa3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_estimate_deepdeep = SOMPZEstimatorDeep.make_stage(name=\"som_deepdeep_estimator\", \n",
    "                                                      model=\"DEMO_romandesc_model_deep.pkl\", \n",
    "                                                      assignment = \"TESTDEMO_deepdata_deep_assign.hdf5\",\n",
    "                                                      aliases=dict(data=\"input_deep_data\"),\n",
    "                                                      data=deepfile,\n",
    "                                                      **deep_som_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac24e3e-b370-42d7-87a0-379267b40e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#som_est_deep.estimate(deep_data)\n",
    "som_estimate_deepdeep.run()\n",
    "som_estimate_deepdeep.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439f51e-69f1-407c-a75e-c90d4a745549",
   "metadata": {},
   "source": [
    "This should create a file `TESTDEMO_deepdata_deep_assign.hdf5`, which will contain the cell assignments (and the som_shape will be carried in the file as well)\n",
    "\n",
    "Now, we can proceed to stages 2) and 3) to make cell assignments for the deep/balrog data to the wide SOM, and the spec data to the deep SOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ca2c4-45c4-46cf-86da-14b7ec13fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "som_estimate_deepwide = SOMPZEstimatorWide.make_stage(name=\"som_deepwide_estimator\", \n",
    "                                           model=\"DEMO_romandesc_model_wide.pkl\", \n",
    "                                           assignment = \"TESTDEMO_deepdata_wide_assign.hdf5\",\n",
    "                                           aliases=dict(data=\"input_deep_data\"),\n",
    "                                           data=deepfile,\n",
    "                                           **wide_som_params)\n",
    "\n",
    "#som_estimate_deepwide.estimate(deep_data)\n",
    "som_estimate_deepwide.run()\n",
    "som_estimate_deepwide.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1143a8c-a3fb-46ef-9a4f-b7eb5b6a9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_estimate_deepspec = SOMPZEstimatorDeep.make_stage(name=\"som_deepspec_estimator\", \n",
    "                                           model=\"DEMO_romandesc_model_deep.pkl\", \n",
    "                                           aliases=dict(assignment=\"cell_deep_spec_data\", data=\"input_spec_data\"),\n",
    "                                           data=specfile,\n",
    "                                           **deep_som_params)\n",
    "\n",
    "#som_estimate_deepspec.estimate(spec_data)\n",
    "som_estimate_deepspec.run()\n",
    "som_estimate_deepspec.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83e231-84ff-440f-93dc-f0f1b27b5114",
   "metadata": {},
   "source": [
    "Next, we will set up the `SOMPZPzc` stage to compute the pz_c weights.  This stage takes several input parameters:<br>\n",
    "`inputs`: the list of the names of columns to be used as inputs<br>\n",
    "`bin_edges`: the list of edges of tomo bins<br>\n",
    "`zbins_min`: minimum redshift for output grid<br>\n",
    "`zbins_max`: maximum redshift for output grid<br>\n",
    "`zbins_dz`: delta z for defining output grid<br>\n",
    "`deep_groupname`: the hdf5_groupname for the deep data<br>\n",
    "`redshift_col`: column name for true redshift in specz sample<br>\n",
    "\n",
    "Also, as we have multiple cell assignment files and data files in the DataStore, note that we are setting up the aliases for the expected inputs for `cell_deep_spec_data` and `spec_data` so that the stage uses the appropriate inputs.  As for where these names come from, we set up `som_estimate_deepspec` as an instance of `SOMPZEstimatorDeep` and assigned it a name with `name=\"som_deepspec_estimator\"`.  The output of `SOMPZEstimatorDeep` and `SOMPZEstimatorWide` are both given the name `assignment` (see the definition of the output in the parent class `SOMPZEstimatorBase` here: https://github.com/LSSTDESC/rail_sompz/blob/3e3a73a4579ef2fd0282087e6cd6d73827f5be35/src/rail/estimation/algos/sompz.py#L1333), which is prepended to the name of the stage, and thus the output in the DataStore is stored as \"assignment_som_deepspec_estimator\".  Similar patterns are used to determine the names of other inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab2950-2157-4fae-87ae-aeb9a77a664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pzcstage = SOMPZPzc.make_stage(name=\"som_pzc_stage\", \n",
    "                               redshift_col=\"redshift\",\n",
    "                               bin_edges=[0.0,0.5,1.0,2.0,3.0],\n",
    "                               zbins_min=0.0,\n",
    "                               zbins_max=3.2,\n",
    "                               zbins_dz=0.02,\n",
    "                               deep_groupname=\"\",\n",
    "                               pz_c=\"TESTDEMO_pz_c.hdf5\",\n",
    "                               aliases=dict(cell_deep_spec_data=\"assignment_som_deepspec_estimator\", spec_data=\"input_spec_data\"),\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f99dc-a96c-4dc6-9e87-1c628acaa9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#pzcstage.estimate(spec_data, cell_deep_spec_data)\n",
    "pzcstage.run()\n",
    "pzcstage.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1830c-896e-440e-8d45-79aca524d7fe",
   "metadata": {},
   "source": [
    "Next, we can estimate the Pc_chat weights.  The only inputs that this stage takes are the deep/balrog assignments for the deep SOM, and the deep/balrog data assignments to the wide SOM.  We will specify these as aliases again to ensure that the code is grabbing the correct data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256eb73-911f-44e7-b015-b8257f49af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcchatstage = SOMPZPc_chat.make_stage(name=\"pcchat_stage\",\n",
    "                                      aliases=dict(cell_deep_balrog_data=\"assignment_som_deepdeep_estimator\",\n",
    "                                                   cell_wide_balrog_data=\"assignment_som_deepwide_estimator\"),\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c9d63-a9f4-4ff0-8ca1-284a9fe26148",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#pcchatstage.estimate(cell_deep_deep_data, cell_deep_wide_data)\n",
    "pcchatstage.run()\n",
    "pcchatstage.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8027bcf-fa92-4b0e-8d4f-8e7df6e28f30",
   "metadata": {},
   "source": [
    "Next, we need to compute more cell assignments, this time for the wide data.  We will start with the wide cell assignments using the wide SOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a6cd1-fa36-4311-9747-e7b7a0c9a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "som_estimate_widewide = SOMPZEstimatorWide.make_stage(name=\"som_widewide_estimator\", \n",
    "                                           model=\"DEMO_romandesc_model_wide.pkl\", \n",
    "                                           assignment = \"TESTDEMO_widedata_wide_assign.hdf5\",\n",
    "                                           aliases=dict(assignment=\"cell_wide_wide_data\", data=\"input_wide_data\"),\n",
    "                                           data=widefile,\n",
    "                                           **wide_som_params)\n",
    "\n",
    "#som_estimate_widewide.estimate(wide_data)\n",
    "som_estimate_widewide.run()\n",
    "som_estimate_widewide.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6fffa9-19c6-42db-956f-8045c8a6fb31",
   "metadata": {},
   "source": [
    "With these cell assignments, we can now compute the pz_chat weights with `SOMPZPzchat`.  This stage takes as inputs some of the same parameters as previous stages, namely, `inputs`, `bin_edges`, `zbins_min`, `zbins_max`, `zbins_dz`, and`redshift_col`.   \n",
    "\n",
    "It also must read in multiple input data files from previous stages, which we can specify in the aliases dictionary.  It requires the spectroscopic data file, the spec data deep SOM cell assignments, the wide data wide SOM cell assignments, the pz_c weights, and the pc_chat weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea13cd2-4f86-4eab-ab69-b24c18d3e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimate_pzchat = SOMPZPzchat.make_stage(name=\"sompz_pzchat\", \n",
    "                                         bin_edges=[0.2, 0.6, 1.2, 1.8, 2.5],\n",
    "                                         zbins_min=0.0,\n",
    "                                         zbins_max=3.0,\n",
    "                                         zbins_dz=0.025,\n",
    "                                         redshift_col=\"redshift\",\n",
    "                                         aliases=dict(spec_data='input_spec_data',\n",
    "                                                      cell_deep_spec_data='assignment_som_deepspec_estimator',\n",
    "                                                      cell_wide_wide_data='assignment_som_widewide_estimator',\n",
    "                                                      pz_c='pz_c_som_pzc_stage',\n",
    "                                                      pc_chat='pc_chat_pcchat_stage',\n",
    "                                                     ),\n",
    "                                         )\n",
    "#estimate_pzchat.estimate(spec_data, cell_deep_spec_data, cell_wide_wide_data, pzchat_data, pcchat_data)\n",
    "estimate_pzchat.run()\n",
    "estimate_pzchat.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6a98e-39b6-4444-950f-508effa9ce80",
   "metadata": {},
   "source": [
    "One last set of cell assignments is needed in order to create tomographic bins, the spectroscopic data assigned to the wide SOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b6c31-f0c2-4a4b-b2f3-6f88afc60b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "som_estimate_widespec = SOMPZEstimatorWide.make_stage(name=\"som_widespec_estimator\", \n",
    "                                           model=\"DEMO_romandesc_model_wide.pkl\", \n",
    "                                           assignment = \"TESTDEMO_specdata_wide_assign.hdf5\",\n",
    "                                           aliases=dict(assignment=\"cell_wide_spec_data\", data=\"input_spec_data\"),\n",
    "                                           **wide_som_params)\n",
    "\n",
    "#som_estimate_widespec.estimate(spec_data)\n",
    "som_estimate_widespec.run()\n",
    "som_estimate_widespec.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17102d9-4acd-4734-ad7e-b058c4df8daa",
   "metadata": {},
   "source": [
    "Now, the penultimate stage, `SOMPZTomobin`, requires the `inputs`, `bin_edges`, `zbins_min`, `zbins_max`, `zbins_dz`, and`redshift_col`, and requires the spectroscopic data and the cell assignment data of the spec data to both the wide and deep SOMs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3284925-7cf4-4eec-9d23-8337ebac2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_tomobin = SOMPZTomobin.make_stage(name=\"sompz_tomobin\",\n",
    "                                           bin_edges=[0.2, 0.6, 1.2, 1.8, 2.5],\n",
    "                                           zbins_min=0.0,\n",
    "                                           zbins_max=3.0,\n",
    "                                           zbins_dz=0.025,\n",
    "                                           wide_som_size=625,\n",
    "                                           deep_som_size=1024,\n",
    "                                           redshift_col=\"redshift\",\n",
    "                                           tomo_bins_wide=\"TESTDEMO_tomo_bins_wide.hdf5\",\n",
    "                                           aliases=dict(spec_data='input_spec_data',\n",
    "                                                        cell_deep_spec_data='assignment_som_deepspec_estimator',\n",
    "                                                        cell_wide_spec_data='assignment_som_widespec_estimator'),\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc92e6-637c-40b4-b1d5-45505ae88418",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#estimate_tomobin.estimate(spec_data, cell_deep_spec_data, cell_wide_spec_data)\n",
    "estimate_tomobin.run()\n",
    "estimate_tomobin.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48855e1c-488f-431a-ab2d-efb0c24bef47",
   "metadata": {},
   "source": [
    "Our final stage, `SOMPZnz` actually outputs the tomographic bin estimates.  It takes the same `inputs`, `bin_edges`, `zbins_min`, `zbins_max`, `zbins_dz`, and`redshift_col` configuration parameters, and requires as inputs the spectroscopic data, the cell assignments of the spec data to the deep SOM, the cell assignments of the wide data to the wide SOM, the tomographic bin assignments from `SOMPZTomobin`, and the pc_chat weights from `SOMPZPc_chat`.  The final output is called `nz` in the stage, we will set that to write out to the file `TESTDEMO_FINAL_NZ.hdf5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beecbc61-a0e9-45ac-a885-1b4d057f9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sompznz_estimate = SOMPZnz.make_stage(name=\"sompz_nz\",\n",
    "                                      bin_edges=[0.2, 0.6, 1.2, 1.8, 2.5],\n",
    "                                      zbins_min=0.0,\n",
    "                                      zbins_max=3.0,\n",
    "                                      zbins_dz=0.025,\n",
    "                                      redshift_col=\"redshift\",\n",
    "                                      aliases=dict(spec_data='input_spec_data',\n",
    "                                                   cell_deep_spec_data='assignment_som_deepspec_estimator',\n",
    "                                                   cell_wide_wide_data='assignment_som_widewide_estimator',\n",
    "                                                   tomo_bins_wide='tomo_bins_wide_sompz_tomobin',\n",
    "                                                   pc_chat='pc_chat_pcchat_stage'),\n",
    "                                      nz=\"TESTDEMO_FINAL_NZ.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac794348-246d-4c6e-9325-56b53ee32a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#sompznz_estimate.estimate(spec_data, cell_deep_spec_data, cell_wide_wide_data, tomo_bins_wide, pcchat_data)\n",
    "sompznz_estimate.run()\n",
    "sompznz_estimate.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20624344-820e-479e-8f26-1c1c25aef766",
   "metadata": {},
   "source": [
    "In this example we specified five tomographic bin edges, [0.2, 0.6, 1.2, 1.8, 2.5], so we should have four tomographic bins. \n",
    "These four tomographic bin estimates are stored in an output file with the name that we assigned to the `SOMPZnz` stage, \"TESTDEMO_FINAL_NZ.hdf5\", let's read in that file and display our tomographic bin estimates, along with the bin edges that we set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39595a-c818-4011-b787-f8e4663d1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206a11e-afb4-44a9-a216-811ac6e6c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = qp.read(\"TESTDEMO_FINAL_NZ.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d6d73-ef96-41c2-9555-fd309d0fdd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "binedges = [0.2, 0.6, 1.2, 1.8, 2.5]\n",
    "fig, axs = plt.subplots(1,1, figsize=(10,6))\n",
    "cols=['r','purple','b','orange']\n",
    "for i, col in enumerate(cols):\n",
    "    ens[i].plot_native(axes=axs, color=col)\n",
    "    axs.axvline(binedges[i+1], color=col, ls='--', lw=0.9)\n",
    "axs.set_xlabel(\"redshift\", fontsize=14)\n",
    "axs.set_ylabel(\"N(z)\", fontsize=14)\n",
    "axs.set_xlim(0,3.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fc716-7f33-4b07-ab71-c73bb50bf007",
   "metadata": {},
   "source": [
    "Looks very good!  Particularly for such small datasets as were used in the example, results should look better with larger files that enable a more well-defined SOM mapping from color to redshift.  There is a nice separation in our tomographic bins, without many bumps outside of the bin due to degeneracies.  The addition of the near-infrared bands can break many of the degeneracies where the Lyman and Balmer breaks are confused for each other.  This demonstrates the power of this technique, and how using NIR (or any other additional band information) can help us in determining our redshift distributions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail_mpi4py",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
