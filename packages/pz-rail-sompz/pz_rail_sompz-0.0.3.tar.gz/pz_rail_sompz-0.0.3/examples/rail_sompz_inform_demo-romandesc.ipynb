{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7959e629-7461-41e7-b0ec-b158f5c5b30b",
   "metadata": {},
   "source": [
    "# RAIL SOMPZ Informer\n",
    "\n",
    "**Author:** Sam Schmidt, Justin Myles\n",
    "\n",
    "**Last Successfully Run:** April 17th, 2025\n",
    "\n",
    "This notebook will demonstrate the training of the \"deep\" and \"wide\" Self-Organized Maps (SOMs) used by `rail_sompz`.  `rail_sompz` is a ported version of the Dark Energy Survey (DES) SOM-based tomographic redshift bin software.\n",
    "This notebook relies on methods and code developed originally for the following publications:\n",
    "\n",
    "[A. Campos et al. (DES Collaboration) - Enhancing weak lensing redshift distribution characterization by optimizing the Dark Energy Survey Self-Organizing Map Photo-z method](https://arxiv.org/pdf/2408.00922)\n",
    "\n",
    "[C. Sánchez, M. Raveri, A. Alarcon, G. Bernstein - Propagating sample variance uncertainties in redshift calibration: simulations, theory, and application to the COSMOS2015 data](https://doi.org/10.1093/mnras/staa2542)\n",
    "\n",
    "[R. Buchs, et al. - Phenotypic redshifts with self-organizing maps: A novel method to characterize redshift distributions of source galaxies for weak lensing](https://doi.org/10.1093/mnras/stz2162)\n",
    "\n",
    "[J. Myles, A. Alarcon, et al. (DES Collaboration) - Dark Energy Survey Year 3 results: redshift calibration of the weak lensing source galaxies](https://doi.org/10.1093/mnras/stab1515)\n",
    "\n",
    "Like other RAIL estimators and summarizers, `rail_sompz` consists of an informer stage and an estimator stage, in this case `SOMPZInformer` and `SOMPZEstimator`.  `SOMPZInformer` takes in a dataset and builds a SOM using that data.  We will need to build two SOMs for sompz, one using \"deep\" data (usually over a smaller area and with additional observed data, e.g. near-infrared bands), and a second SOM trained on \"wide\" data.  \n",
    "\n",
    "There are a number of **configuration parameters** that the stage uses to control aspects of the SOM training:\n",
    "- redshift_col: the name of the redshift column\n",
    "- hdf5_groupname: the hdf5_groupname for data\n",
    "- inputs: the list of the names of columns to be used as inputs for the data\n",
    "- input_errs: the list of the names of columns containing errors on inputs for the data\n",
    "- zero_points: the list of zero points for converting mags to fluxes for the data, if needed\n",
    "- som_shape: a tuple defining the shape for the som, must be a 2-element tuple, e.g. `(32, 32)`\n",
    "- som_minerror: the floor value placed on observational error on each feature in the som\n",
    "- som_wrap: boolean flag to set whether the SOM has periodic boundary conditions\n",
    "- som_take_log: boolean flag to set whether to take log of inputs (i.e. for fluxes) for the som\n",
    "- convert_to_flux: boolean flag for whether to convert input columns to fluxes for the data, set to true if inputs are mags and to False if inputs are already fluxes\n",
    "- set_threshold: boolean flag for whether to replace values below a threshold with a set number\n",
    "- thresh_val_deep: threshold value for set_threshold for the data\n",
    "\n",
    "We will set several of these values in our example, any values not explicitly set will revert to their defaults.  \n",
    "\n",
    "Let's start by importing a few packages, including `SOMPZInformer` and setting up the RAIL DataStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9463120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# usual imports\n",
    "import os\n",
    "import numpy as np\n",
    "#from rail.core.utils import RAILDIR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e5a23-c2cf-40df-ab43-ca26a4fd78ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rail.estimation.algos.sompz import SOMPZInformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ba7eb-9b07-4284-8885-9ca0aa6b0585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01f0ea-3687-4725-bc26-9d65d3100482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa375-a847-4482-9a68-763f3cf4849d",
   "metadata": {},
   "source": [
    "Next, let's read in some test data. We'll use some small datasets drawn from the Roman-DESC simulations, and where we have incorporated expected 10-year depth photometric uncertainties into the data via the photerr-based error models in RAIL.\n",
    "\n",
    "The SOMPZ method usually leverages a \"deep\" dataset with extra bands (often in the near-infrared), where the extra photometric information in the extended wavelength coverage enables a magnitudes/colors -> redshift mapping with less degeneracies than when using optical colors along.  For this demo, we will use data from the Rubin-Roman simulation [Citation needed!], which does contain simluated photometry for both the Rubin optical `ugrizy` bands as well as the Roman `JHFK` bands.  The Roman `J`, `H`, `F`, and `K` bands have central wavelengths of approximately 1.29, 1.58, 1.84, and 2.13 microns respectively.\n",
    "\n",
    "We have prepared several data files consisting of simulated Roman-DESC data, the cell below contains (commented) commands to fetch those files from NERSC.  There are two sets of files included in the tar file, one set contains 37,500 \"specz\" galaxies (which are a subset of a set of 75,000 \"deep/balrog\" galaxies, and a set of 100,000 \"wide field\" galaxies.  The other set consists of a subset of these galaxies where we only take 5% of each of the larger samples (so 1875 specz, 3750 \"deep\", and 5000 \"wide\" galaxies.  The larger files will give a more robust mapping in our SOM given the extra training data, but will take longer.  The smaller files will give results that do not look as nice, but are large enough to showcase the method while running much faster.  You can comment or uncomment the three files in the cells below to switch from the \"small\" files to the \"large\" files if you do not mind some extra run time.\n",
    "\n",
    "For the \"deep\" SOM, the data file is named `romandesc_deep_data_37c_noinf.hdf5` and includes the LSST `ugrizy` bands as well as the Roman `JHF` bands (we leave off the K-band for simplicity), for a total of **nine** bands.  The extra near-infrared information in the `JHF` bands will be crucial in mapping out the color to redshift relation for our deep sample.   The galaxies in this file are trimmed to include only galaxies with i<25.0.  This sample size is smaller than those that we will typically use, but enough for a functional example.\n",
    "\n",
    "\n",
    "For the \"wide\" som, the data file is named `romandesc_wide_data_50c_noinf.hdf5` and we will only use the `ugrizy` bands in the analysis.  There are 5000 galaxies in this file.\n",
    "\n",
    "The cell below, if uncommented, will fetch a tar file from NERSC and copy the files to a subdirectory named DEMODATA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe30b9-9eea-4aba-8190-e1e607716390",
   "metadata": {},
   "source": [
    "### Uncomment the commands in the cell below to grab the data files to run this demo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41e93e-6d4d-4f49-93d4-f17f873319e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -O https://portal.nersc.gov/cfs/lsst/PZ/roman_desc_demo_data.tar.gz\n",
    "!mkdir DEMODATA\n",
    "!tar -xzvf roman_desc_demo_data.tar.gz\n",
    "!mv romandesc*.hdf5 DEMODATA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790f316-226d-4518-8d57-dba4e622f21e",
   "metadata": {},
   "source": [
    "Now, let's add our deep and wide datasets to the DataStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bb980-447f-461c-bbe3-72e57cb9e9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the demo to run quickly on the small files, leave these to lines uncommented\n",
    "trainFileDeep = './DEMODATA/romandesc_deep_data_37c_noinf.hdf5'\n",
    "trainFileWide = './DEMODATA/romandesc_wide_data_50c_noinf.hdf5'\n",
    "# to switch to larger files that will take a bit longer but yield slightly better results\n",
    "# switch to these two larger files\n",
    "#trainFileDeep = './DEMODATA/romandesc_deep_data_75k_noinf.hdf5'\n",
    "#trainFileWide = './DEMODATA/romandesc_wide_data_100k_noinf.hdf5'\n",
    "deep_data = DS.read_file(\"input_deep_data\", TableHandle, trainFileDeep)\n",
    "wide_data = DS.read_file(\"input_wide_data\", TableHandle, trainFileWide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ad14f-0d8d-47f9-bb74-14a913829a62",
   "metadata": {},
   "source": [
    "Let's take a look at what the names of the columns are in the deep file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eda622-abe1-4e56-9e54-238840cb91ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('\\n'.join(sorted(deep_data().keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3d490-115c-4ba3-94e2-c4d37e0b9e37",
   "metadata": {},
   "source": [
    "We have the Rubin `ugrizy` bands and their errors with names like `u` and `u_err`, the Roman NIR bands `YJHF` and their errors, and the colors for adjacent bands, e.g. `ug` is really `u-g`.  We will use just the magnitude quantities and not the colors when constructing our example SOM (for more information on this choice, see the Appendix A of Sánchez et al. 2020) .  For our \"deep\" SOM we will use all of `ugrizyJHF`, while for the \"wide\" SOM we will use only `ugrizy`.  Let's set up some lists with our magnitudes that will be used in our configs.  The SOM also requires a zero point if we are going to convert to flux (which we are), so we will supply default zero points of 30.0 for all bands in this demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bd934-ed4b-4c83-9b63-85d07bea735e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y','J','H','F']\n",
    "\n",
    "deepbands = []\n",
    "deeperrs = []\n",
    "zeropts = []\n",
    "for band in bands:\n",
    "    deepbands.append(f'{band}')\n",
    "    deeperrs.append(f'{band}_err')\n",
    "    zeropts.append(30.)\n",
    "\n",
    "widebands = []\n",
    "wideerrs = []  \n",
    "for band in bands[:6]:\n",
    "    widebands.append(f'{band}')\n",
    "    wideerrs.append(f'{band}_err')\n",
    "    \n",
    "refband_deep=deepbands[3]\n",
    "refband_wide=widebands[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591505b-e76b-4e96-82cb-78cdc54249f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(deepbands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfde11-f43d-4c0b-a4c7-8c88e1cd82b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(widebands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796070e-548f-42f0-a1ab-719fa13e4733",
   "metadata": {},
   "source": [
    "Next, let's make a dictionary of the parameters that we'll feed into the informer for the deep SOM and wide SOM, including the non-default names of the input columns (`inputs_deep`) and the errors (`input_errs_deep`) and their wide counterparts.  We'll feed in a list for the zero points (`zero_points`) as well.  We want to convert to flux so we set `convert_to_flux_deep` and `convert_to_flux_wide` to `True`.  We will also apply a threshold cut to the deep SOM by setting `set_threshold_deep` to `True` and set the threshold value with `thresh_val_deep` = 1.e-5.  We can set the shape of the SOMs or let them take their default values.  Let's leave the \"deep\" SOM with its default size of `(32, 32)` by not supplying a value, and change the \"wide\" SOM size with `som_shape_wide=(25,25)`.  If your input data is flux-like (which ours is not) and want it to look more magnitude-like, you can set  `som_take_log_wide` to `True` if you want to take the log of the data before creating the SOM.  We will set this to `False`, as we want to work in converted flux space.  And, finally `som_wrap_wide` sets whether or not to use periodic boundaries in the SOM, we will set this to `False` for the wide SOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a722208-6dbf-469c-921d-969ed78aa5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "som_params_deep = dict(inputs=deepbands, input_errs=deeperrs,\n",
    "                  zero_points=zeropts, \n",
    "                  convert_to_flux=True, set_threshold=True, \n",
    "                  thresh_val=1.e-5, som_shape=(32,32),\n",
    "                  som_minerror=0.005,\n",
    "                  som_take_log=False, som_wrap=False)\n",
    "\n",
    "som_params_wide = dict(inputs=widebands, input_errs=wideerrs,\n",
    "                  convert_to_flux=True, \n",
    "                  som_shape=(25, 25), som_minerror=0.005,\n",
    "                  som_take_log=False, som_wrap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0560e-2891-47b7-a24b-a6311dc08056",
   "metadata": {},
   "source": [
    "If you have used other RAIL packages you may have seen `hdf5_groupname` as a parameter where you may specify an HDF5 group where your input data may live.  In our example data, our magnitudes are in the top level of the HDF5 file and not in a sub-group, so we will set `hdf5_groupname` to `\"\"` to reflect this.\n",
    "\n",
    "We will also supply the `model` config parameter, which will set the name for the pickle file that will hold our output model consisting of the SOM.  First, we will run the informer for the deep SOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abc0e5-1408-4bf7-ba4f-df6994285a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "som_inform_deep = SOMPZInformer.make_stage(name=\"som_informer_deep\", \n",
    "                                      hdf5_groupname=\"\", \n",
    "                                      model=\"DEMO_romandesc_model_deep.pkl\", **som_params_deep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a7222-68e2-422a-b71a-f7fdfbb13a27",
   "metadata": {},
   "source": [
    "Now, run the informer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18fbfe-a72d-4c1c-86bd-1e2462686cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "som_inform_deep.inform(deep_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5081d-63e4-4953-94e4-2bcbe6586c5b",
   "metadata": {},
   "source": [
    "Next, let's set up and inform the inform stage for our second \"wide\" SOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9814e2d-f173-4134-a04e-f3d18c7002f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_inform_wide = SOMPZInformer.make_stage(name=\"som_informer_wide\", \n",
    "                                      hdf5_groupname=\"\", \n",
    "                                      model=\"DEMO_romandesc_model_wide.pkl\", **som_params_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df527f5c-0d0c-4735-b035-a18f67612cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_inform_wide.inform(wide_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22853e-ae95-4977-b1a9-08b86c50382c",
   "metadata": {},
   "source": [
    "Our small samples of 3750 deep and 5000 wide galaxies should take under a minute each to train, and should create files named `DEMO_romandesc_model_deep.pkl` and `DEMO_romandesc_model_wide.pkl`.  Let's look at the results by reading in the deep model we just wrote out, and see what it contains.  It should be a dictionary that contains the som as `som`, as well as the `columns` and `err_columns` lists.  We store these column names as they basically define the ordering of the columns and errors, and we'll want that the same for data that we pass in for the estimation stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a40ca-50d4-4045-93a4-e28564e75817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526df18a-a12e-4d75-b832-4ad270909b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"DEMO_romandesc_model_deep.pkl\", \"rb\") as f:\n",
    "    deep_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ad484-9c9d-4d40-8f20-29f2ee3a101c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a02500-a1f2-4799-9305-df91e467707f",
   "metadata": {},
   "source": [
    "There are some handy plotting functions available in the `rail.estimation.algos.som.py` file that enable us to visualize our SOM for some basic visual checks.  Let's first plot the occupation of cells broken up by colors, i.e. the mean values of g-i, i-y, u-g, and the i-band magnitude for each cell.  First, the deep SOM (using the `somDomainColorsnok` to plot quantities using only have ugrizy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357e9a4-ffc8-4ad5-98e9-1f03d5de4064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rail.estimation.algos.som as SOMFUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a64836-a4a9-4e8e-8c37-d80f681eb699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOMFUNCS.somDomainColorsnok(deep_model['som'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc24ced-1680-4b6a-9842-e397ae6d6853",
   "metadata": {},
   "source": [
    "And now, for the deep SOM using `somDomainColors` which shows i-K in the upper right(in actuality i-F, the names are currently hardcoded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e1ae8-19cc-42c4-b400-6bac5ab444b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOMFUNCS.somDomainColors(deep_model['som'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537bc500-1dbb-4a74-9e5b-07d7434a92e8",
   "metadata": {},
   "source": [
    "For comparison, here is the `somDomainColorsnok` plots for the wide SOM.  First, we'll have to load that model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06e2b9-e51f-46c8-9efe-e3b806662af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DEMO_romandesc_model_wide.pkl\", \"rb\") as f:\n",
    "    wide_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad36ec-85e9-44b7-a4b2-fef371f63130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOMFUNCS.somDomainColorsnok(wide_model['som'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335e3a7-eab5-45f7-ba0d-b4a357c9f585",
   "metadata": {},
   "source": [
    "And, as a final visualization, here are the locations of the mean colors of each SOM cell in i-K vs g-i color space, color-coded by the mean i-band magnitude of the SOM cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4920cf5-6d83-40a5-bad6-26f2a9b2d24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOMFUNCS.somPlot2d(deep_model['som'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b342745-5c4c-425a-846c-a9b5cce417ec",
   "metadata": {},
   "source": [
    "This looks promising, our SOMs both show coherent patterns in color and magnitude, as they should, and will enable us to map color-space to redshift via the occupation of training galaxies in the SOMs.  In a separate notebook, `rail_sompz_estimation_demo.ipynb`, we will run the estimator stage and produce tomographic bin estimates for a test set of objects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAIL",
   "language": "python",
   "name": "rail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
