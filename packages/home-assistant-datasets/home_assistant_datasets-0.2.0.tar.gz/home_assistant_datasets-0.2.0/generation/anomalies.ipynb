{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from home_assistant_datasets.secrets import get_secret\n",
    "from home_assistant_datasets import model_client\n",
    "\n",
    "MODEL_ID = \"gpt-3.5-turbo-0125\"\n",
    "os.environ['SECRETS_FILE'] = '../secrets.yaml'\n",
    "\n",
    "openai = openai.OpenAI(api_key=get_secret(\"openai_api_key\"))\n",
    "model = model_client.ModelClient(openai, MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read seed data\n",
    "\n",
    "The seed data for the prompt is manually curated to use as examples for further synthetic data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "SEEDS_DIR = pathlib.Path(\"./seeds/\")\n",
    "ANOMALIES_FILE = SEEDS_DIR / \"anomalies.yaml\"\n",
    "\n",
    "with open(ANOMALIES_FILE) as f:\n",
    "    anomaly_dataset = list(yaml.load_all(f.read(), Loader=yaml.Loader))\n",
    "\n",
    "normal = []\n",
    "anomaly = []\n",
    "for ds in anomaly_dataset:\n",
    "    if 'normal' in ds:\n",
    "        normal.extend(ds['normal'])\n",
    "    if 'anomaly' in ds:\n",
    "        anomaly.extend(ds['anomaly'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANAMOLIES_PROMPT = f\"\"\"\n",
    "You are generating synthetic data to used to train models for Home Assistant\n",
    "and used to evaluate things like generating a summary, performing home automation\n",
    "actions, or for generating other synthetic data.\n",
    "\n",
    "The data should describe the current state of an area in a home and be classified as\n",
    "\"Normal\" or \"Anomaly.\"\n",
    "\n",
    "Generate a balanced dataset with a significant portion of normal entries and a smaller\n",
    "portion of anomalies. Anomalies should cover a variety of scenarios related to security,\n",
    "climate control, appliances, sensors, and unusual activity. Consider including different\n",
    "combinations of sensor and device states for richer data. Ensure the data reflects realistic\n",
    "variations in sensor readings based on factors like time of day and season.\n",
    "\n",
    "The user will give you some examples classifications and you generate more.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped 641: 100%|██████████| 40/40 [06:32<00:00,  9.82s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Any\n",
    "import itertools\n",
    "\n",
    "import yaml\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import slugify\n",
    "\n",
    "# How many samples to generate\n",
    "N_DATAPOINTS = 10\n",
    "NUM_NORMAL = 15\n",
    "NUM_ANOMALY = 5\n",
    "ANOMALY = \"Anomaly: \"\n",
    "NORMAL = \"Normal: \"\n",
    "\n",
    "DATASET_DIR = pathlib.Path(\"../datasets/\")\n",
    "ANOMALY_OUTPUT_DIR = DATASET_DIR / \"anomaly\"\n",
    "\n",
    "# Wipe existing areas\n",
    "shutil.rmtree(ANOMALY_OUTPUT_DIR, ignore_errors=True)\n",
    "ANOMALY_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def make_seed_items() -> str:\n",
    "    \"\"\"Generate seed items for the generation prompt.\"\"\"\n",
    "    items = [\n",
    "        *[\n",
    "            f\"{ANOMALY}{item}\"\n",
    "            for item in random.choices(normal, k=NUM_NORMAL)\n",
    "        ],\n",
    "        *[\n",
    "            f\"{NORMAL}{item}\"\n",
    "            for item in random.choices(anomaly, k=NUM_NORMAL)\n",
    "        ],\n",
    "    ]\n",
    "    random.shuffle(items)\n",
    "    return \"\\n\".join(items)\n",
    "\n",
    "\n",
    "skipped = 0\n",
    "with tqdm(total=N_DATAPOINTS) as pbar:\n",
    "    for i in range(0, N_DATAPOINTS):\n",
    "        with open(ANOMALY_OUTPUT_DIR / f\"anomalies-{i}.yaml\", \"w\") as output:\n",
    "            seeds = make_seed_items()\n",
    "            prompt = ANAMOLIES_PROMPT.format(seeds=seeds)\n",
    "\n",
    "            response_obj = None\n",
    "            for i in range(0, 3):\n",
    "                response = model.complete(ANAMOLIES_PROMPT, prompt)\n",
    "                try:\n",
    "                    response_obj = yaml.safe_load(response)\n",
    "                    break\n",
    "                except yaml.YAMLError as exc:\n",
    "                    continue\n",
    "\n",
    "            anomaly_response = []\n",
    "            normal_response = []\n",
    "            for line in response.splitlines():\n",
    "                if line.startswith(ANOMALY):\n",
    "                    anomaly_response.append(line.lstrip(ANOMALY))\n",
    "                elif line.startswith(NORMAL):\n",
    "                    normal_response.append(line.lstrip(NORMAL))\n",
    "                else:\n",
    "                    skipped += 1\n",
    "            update = {\n",
    "                \"normal\": normal_response,\n",
    "                \"anomaly\": anomaly_response,\n",
    "            }\n",
    "            output.write(yaml.dump(update, explicit_start=True, sort_keys=False))\n",
    "            output.flush()\n",
    "\n",
    "            pbar.set_description(f\"Skipped {skipped}\")\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for in_file in ANOMALY_OUTPUT_DIR.glob(\"anomalies-*.yaml\"):\n",
    "    docs = list(yaml.load_all(in_file.read_bytes(), Loader=yaml.Loader))\n",
    "    for doc in docs:\n",
    "        for entry in doc.get(\"normal\", []):\n",
    "            records.append({\n",
    "                \"summary\": entry,\n",
    "                \"label\": \"normal\",\n",
    "            })\n",
    "        for entry in doc.get(\"anomaly\", []):\n",
    "            records.append({\n",
    "                \"summary\": entry,\n",
    "                \"label\": \"anomaly\",\n",
    "            })\n",
    "\n",
    "random.shuffle(records)\n",
    "update = {\"records\": records}\n",
    "with (ANOMALY_OUTPUT_DIR / \"anomalies.yaml\").open(\"w\") as output:\n",
    "    output.write(yaml.dump(update, explicit_start=True, sort_keys=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
