---
- model_id-task_name: claude-3-5-haiku-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-5-haiku-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-5-haiku-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-5-haiku-eval-test_expected_states
  good_percent: 85.4%
  confidence_interval: 3.2%
  good: 392
  total: 459
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-7-sonnet-eval-test_expected_states
  good_percent: 89.4%
  confidence_interval: 2.9%
  good: 390
  total: 436
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expected_states
  good_percent: 88.9%
  confidence_interval: 2.9%
  good: 409
  total: 460
- model_id-task_name: gemini-2.0-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-eval-test_expected_states
  good_percent: 68.7%
  confidence_interval: 4.2%
  good: 316
  total: 460
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expected_states
  good_percent: 65.9%
  confidence_interval: 4.3%
  good: 303
  total: 460
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expected_states
  good_percent: 88.7%
  confidence_interval: 2.9%
  good: 408
  total: 460
- model_id-task_name: gemini-2.5-pro-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-pro-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-pro-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-pro-eval-test_expected_states
  good_percent: 91.3%
  confidence_interval: 2.6%
  good: 421
  total: 461
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expected_states
  good_percent: 86.5%
  confidence_interval: 3.1%
  good: 398
  total: 460
- model_id-task_name: gpt-4.1-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-eval-test_expected_states
  good_percent: 81.2%
  confidence_interval: 3.6%
  good: 375
  total: 462
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expected_states
  good_percent: 86.3%
  confidence_interval: 3.1%
  good: 396
  total: 459
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expected_states
  good_percent: 74.7%
  confidence_interval: 4.0%
  good: 342
  total: 458
- model_id-task_name: gpt-4o-mini-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4o-mini-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4o-mini-eval-test_expect_response
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4o-mini-eval-test_expected_states
  good_percent: 85.9%
  confidence_interval: 3.2%
  good: 395
  total: 460

