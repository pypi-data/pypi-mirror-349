---
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_response
  good_percent: 69.4%
  confidence_interval: 4.8%
  good: 243
  total: 350
- model_id-task_name: gemini-1.5-flash-eval-test_expected_states
  good_percent: 95.0%
  confidence_interval: 9.6%
  good: 19
  total: 20
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_response
  good_percent: 61.7%
  confidence_interval: 5.1%
  good: 216
  total: 350
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expected_states
  good_percent: 90.0%
  confidence_interval: 13.1%
  good: 18
  total: 20
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_response
  good_percent: 74.6%
  confidence_interval: 4.6%
  good: 261
  total: 350
- model_id-task_name: gemini-2.5-flash-eval-test_expected_states
  good_percent: 80.0%
  confidence_interval: 17.5%
  good: 16
  total: 20
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_response
  good_percent: 74.0%
  confidence_interval: 4.6%
  good: 259
  total: 350
- model_id-task_name: gpt-3.5-eval-test_expected_states
  good_percent: 60.0%
  confidence_interval: 21.5%
  good: 12
  total: 20
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_response
  good_percent: 83.1%
  confidence_interval: 3.9%
  good: 291
  total: 350
- model_id-task_name: gpt-4.1-mini-eval-test_expected_states
  good_percent: 90.0%
  confidence_interval: 13.1%
  good: 18
  total: 20
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_response
  good_percent: 77.4%
  confidence_interval: 4.4%
  good: 271
  total: 350
- model_id-task_name: gpt-4.1-nano-eval-test_expected_states
  good_percent: 50.0%
  confidence_interval: 21.9%
  good: 10
  total: 20

