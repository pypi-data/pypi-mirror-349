---
- model_id-task_name: claude-3-5-haiku-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-5-haiku-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-5-haiku-eval-test_expect_response
  good_percent: 86.3%
  confidence_interval: 5.1%
  good: 151
  total: 175
- model_id-task_name: claude-3-5-haiku-eval-test_expected_states
  good_percent: 100.0%
  confidence_interval: 0.0%
  good: 10
  total: 10
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: claude-3-7-sonnet-eval-test_expect_response
  good_percent: 83.1%
  confidence_interval: 5.7%
  good: 138
  total: 166
- model_id-task_name: claude-3-7-sonnet-eval-test_expected_states
  good_percent: 100.0%
  confidence_interval: 0.0%
  good: 10
  total: 10
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-1.5-flash-eval-test_expect_response
  good_percent: 64.6%
  confidence_interval: 7.1%
  good: 113
  total: 175
- model_id-task_name: gemini-1.5-flash-eval-test_expected_states
  good_percent: 90.0%
  confidence_interval: 18.6%
  good: 9
  total: 10
- model_id-task_name: gemini-2.0-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-eval-test_expect_response
  good_percent: 77.7%
  confidence_interval: 6.2%
  good: 136
  total: 175
- model_id-task_name: gemini-2.0-flash-eval-test_expected_states
  good_percent: 90.0%
  confidence_interval: 18.6%
  good: 9
  total: 10
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expect_response
  good_percent: 57.1%
  confidence_interval: 7.3%
  good: 100
  total: 175
- model_id-task_name: gemini-2.0-flash-lite-eval-test_expected_states
  good_percent: 90.0%
  confidence_interval: 18.6%
  good: 9
  total: 10
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-flash-eval-test_expect_response
  good_percent: 69.7%
  confidence_interval: 6.8%
  good: 122
  total: 175
- model_id-task_name: gemini-2.5-flash-eval-test_expected_states
  good_percent: 60.0%
  confidence_interval: 30.4%
  good: 6
  total: 10
- model_id-task_name: gemini-2.5-pro-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-pro-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gemini-2.5-pro-eval-test_expect_response
  good_percent: 82.3%
  confidence_interval: 5.7%
  good: 144
  total: 175
- model_id-task_name: gemini-2.5-pro-eval-test_expected_states
  good_percent: 100.0%
  confidence_interval: 0.0%
  good: 10
  total: 10
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-3.5-eval-test_expect_response
  good_percent: 74.1%
  confidence_interval: 6.5%
  good: 129
  total: 174
- model_id-task_name: gpt-3.5-eval-test_expected_states
  good_percent: 40.0%
  confidence_interval: 30.4%
  good: 4
  total: 10
- model_id-task_name: gpt-4.1-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-eval-test_expect_response
  good_percent: 84.6%
  confidence_interval: 5.4%
  good: 148
  total: 175
- model_id-task_name: gpt-4.1-eval-test_expected_states
  good_percent: 100.0%
  confidence_interval: 0.0%
  good: 10
  total: 10
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-mini-eval-test_expect_response
  good_percent: 79.4%
  confidence_interval: 6.0%
  good: 139
  total: 175
- model_id-task_name: gpt-4.1-mini-eval-test_expected_states
  good_percent: 100.0%
  confidence_interval: 0.0%
  good: 10
  total: 10
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4.1-nano-eval-test_expect_response
  good_percent: 68.0%
  confidence_interval: 6.9%
  good: 119
  total: 175
- model_id-task_name: gpt-4.1-nano-eval-test_expected_states
  good_percent: 50.0%
  confidence_interval: 31.0%
  good: 5
  total: 10
- model_id-task_name: gpt-4o-mini-eval-test_expect_llm_tool_call_args
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4o-mini-eval-test_expect_llm_tool_call_name
  good_percent: 0.0%
  confidence_interval: 0.0%
  good: 0
  total: 0
- model_id-task_name: gpt-4o-mini-eval-test_expect_response
  good_percent: 76.6%
  confidence_interval: 6.3%
  good: 134
  total: 175
- model_id-task_name: gpt-4o-mini-eval-test_expected_states
  good_percent: 50.0%
  confidence_interval: 31.0%
  good: 5
  total: 10

