{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99af22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d12a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from camar import camar_v0\n",
    "from rrt import RRT\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import trange\n",
    "\n",
    "from camar.render import SVG_Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9acc9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_name = \"random_grid_h20_w20_a8_o60\"\n",
    "with open(f\"BenchMARL/benchmarl/conf/task/camar/{yaml_name}.yaml\") as stream:\n",
    "    try:\n",
    "        env_kwargs = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "env_kwargs[\"map_generator\"] = \"_\".join(yaml_name.split(\"_\")[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da340cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 100\n",
    "rrt_iters = 50_000\n",
    "visualize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2302cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kp = 1.7\n",
    "Kd = 0.05\n",
    "\n",
    "@jax.jit\n",
    "def pd_control(target_pos, pos, vel):\n",
    "    error = target_pos - pos\n",
    "    # Assuming desired velocity is zero at intermediate points,\n",
    "    # except for final point if you want a nonzero velocity.\n",
    "\n",
    "    # target_vel = target_pos - pos\n",
    "    # target_vel = target_vel / (jnp.linalg.norm(target_vel) + 1e-8)\n",
    "\n",
    "    target_vel = 0.0\n",
    "\n",
    "    error = error / (jnp.linalg.norm(error) + 1e-8)\n",
    "\n",
    "    error_vel = target_vel - vel\n",
    "    # Simple PD control law\n",
    "    force = Kp * error + Kd * error_vel\n",
    "    return force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8cc4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f2a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [39:27<00:00, 23.67s/it]\n"
     ]
    }
   ],
   "source": [
    "env = camar_v0(**env_kwargs)\n",
    "rrt_ = RRT(env, rrt_iters, env.agent_rad)\n",
    "\n",
    "success_rate_s = []\n",
    "flowtime_s = []\n",
    "makespan_s = []\n",
    "coordination_s = []\n",
    "for env_id in trange(num_envs):\n",
    "    key, _key = jax.random.split(key, 2)\n",
    "    obs, state = env.reset(_key)\n",
    "\n",
    "    # print(env_id, \"run rrt\")\n",
    "    rrt_state = rrt_.run(_key, state.agent_pos, state.goal_pos, state.landmark_pos)\n",
    "    last_idx = rrt_.find_last_idx(rrt_state)\n",
    "\n",
    "    path_ids = []\n",
    "    for agent in range(env.num_agents):\n",
    "        agent_path = []\n",
    "        i = int(last_idx[agent])\n",
    "        if i == -1:\n",
    "            agent_path.append(0)\n",
    "        else:\n",
    "            while i != -1:\n",
    "                agent_path.append(i)\n",
    "                i = int(rrt_state.parent[i, agent])\n",
    "        path_ids.append(agent_path[::-1])\n",
    "\n",
    "    current_waypoint_idx = [0 for _ in range(env.num_agents)]\n",
    "    tolerance = env.goal_rad\n",
    "\n",
    "    if visualize:\n",
    "        state_seq = [state]\n",
    "    # print(\"run steps\")\n",
    "    for _ in range(env.max_steps + 1):\n",
    "        target_pos = []\n",
    "        for agent, cur_idx in enumerate(current_waypoint_idx):\n",
    "            target_pos.append(rrt_state.pos[path_ids[agent][cur_idx], agent])\n",
    "        target_pos = jnp.stack(target_pos)\n",
    "\n",
    "        # Compute the control force (this could be LQR instead)\n",
    "        force = pd_control(target_pos, state.agent_pos, state.agent_vel)\n",
    "        # print(force)\n",
    "\n",
    "        _key, key_s = jax.random.split(_key)\n",
    "\n",
    "        obs, state, reward, done, _ = env.step(key_s, state, force)\n",
    "\n",
    "        if visualize:\n",
    "            state_seq.append(state)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        cur_dist = jnp.linalg.norm(target_pos - state.agent_pos, axis=-1)\n",
    "\n",
    "        for agent, dist in enumerate(cur_dist):\n",
    "            if dist < tolerance:\n",
    "                if current_waypoint_idx[agent] < len(path_ids[agent]) - 1:\n",
    "                    current_waypoint_idx[agent] += 1\n",
    "\n",
    "    if visualize:\n",
    "        break\n",
    "\n",
    "    success_rate = state.on_goal.mean()\n",
    "    flowtime = state.time_to_reach_goal.sum()\n",
    "    makespan = state.time_to_reach_goal.max()\n",
    "    coordination =  1 - (state.num_collisions / state.step).mean()\n",
    "\n",
    "    success_rate_s.append(float(success_rate))\n",
    "    flowtime_s.append(float(flowtime))\n",
    "    makespan_s.append(float(makespan))\n",
    "    coordination_s.append(float(coordination))\n",
    "\n",
    "if not visualize:\n",
    "    df_metrics = pd.DataFrame({\n",
    "    \"success_rate\": success_rate_s,\n",
    "    \"flowtime\": flowtime_s,\n",
    "    \"makespan\": makespan_s,\n",
    "    \"coordination\": coordination_s,\n",
    "    })\n",
    "    df_metrics.to_csv(f\"metrics_rrt/{yaml_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea907214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ True, False,  True,  True, False,  True,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrt_state.goal_reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235dd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    SVG_Visualizer(env, state_seq, animate_landmarks=False).save_svg(\"test_rrt.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
