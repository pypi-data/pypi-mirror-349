{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    }
   ],
   "source": [
    "# %env XLA_PYTHON_CLIENT_MEM_FRACTION=0.4\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbf9799e510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tensordict import TensorDictBase\n",
    "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import RandomSampler, ReplayBuffer\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import RewardSum, TransformedEnv, set_exploration_type, ExplorationType\n",
    "from torchrl.modules import (\n",
    "\tAdditiveGaussianModule,\n",
    "\tMultiAgentMLP,\n",
    "\tProbabilisticActor,\n",
    "\tTanhDelta,\n",
    ")\n",
    "from torchrl.objectives import DDPGLoss, SoftUpdate, ValueEstimators\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ISAC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "frames_per_batch = 27_000\n",
    "n_iters = 100\n",
    "total_frames = frames_per_batch * n_iters\n",
    "\n",
    "# Replay buffer\n",
    "memory_size = 1_000_000\n",
    "\n",
    "n_optimiser_steps = 200\n",
    "train_batch_size = 500\n",
    "lr = 3e-4\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "gamma = 0.99\n",
    "polyak_tau = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_env.core.environment import Env\n",
    "from rl_env.torchrl.torchrl_wrapper import MyEnvWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 10\n",
    "height = 10\n",
    "obstacle_density = 0.0\n",
    "num_agents = 5\n",
    "grain_factor = 6\n",
    "\n",
    "env = Env(\n",
    "\t\twidth=width,\n",
    "\t\theight=height,\n",
    "\t\tobstacle_density=obstacle_density,\n",
    "\t\tnum_agents=num_agents,\n",
    "\t\tgrain_factor=grain_factor,\n",
    "\t\tcontact_force=500,\n",
    "\t\tcontact_margin=1e-3,\n",
    "\t\tdt=0.01,\n",
    "\t\tmax_steps=900,\n",
    "\t\tframeskip=7,\n",
    "\t\tmax_obs=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_envs = 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "795726461"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_envs = frames_per_batch // env.max_steps\n",
    "print(\"num_envs =\", num_envs)\n",
    "\n",
    "env = MyEnvWrapper(env, device=device, batch_size=[num_envs])\n",
    "env.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec:\n",
      " Composite(\n",
      "    agents: Composite(\n",
      "        action: BoundedContinuous(\n",
      "            shape=torch.Size([30, 5, 2]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([30, 5, 2]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([30, 5, 2]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
      "            device=cuda:0,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cuda:0,\n",
      "        shape=torch.Size([30, 5])),\n",
      "    device=cuda:0,\n",
      "    shape=torch.Size([30])) \n",
      "\n",
      "reward_spec:\n",
      " Composite(\n",
      "    agents: Composite(\n",
      "        reward: BoundedContinuous(\n",
      "            shape=torch.Size([30, 5, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([30, 5, 1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([30, 5, 1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
      "            device=cuda:0,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cuda:0,\n",
      "        shape=torch.Size([30, 5])),\n",
      "    device=cuda:0,\n",
      "    shape=torch.Size([30])) \n",
      "\n",
      "done_spec:\n",
      " Composite(\n",
      "    done: Categorical(\n",
      "        shape=torch.Size([30, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cuda:0,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    terminated: Categorical(\n",
      "        shape=torch.Size([30, 1]),\n",
      "        space=CategoricalBox(n=2),\n",
      "        device=cuda:0,\n",
      "        dtype=torch.bool,\n",
      "        domain=discrete),\n",
      "    device=cuda:0,\n",
      "    shape=torch.Size([30])) \n",
      "\n",
      "observation_spec:\n",
      " Composite(\n",
      "    agents: Composite(\n",
      "        observation: UnboundedContinuous(\n",
      "            shape=torch.Size([30, 5, 18]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([30, 5, 18]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([30, 5, 18]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
      "            device=cuda:0,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cuda:0,\n",
      "        shape=torch.Size([30, 5])),\n",
      "    device=cuda:0,\n",
      "    shape=torch.Size([30])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"action_spec:\\n\", env.full_action_spec, \"\\n\")\n",
    "print(\"reward_spec:\\n\", env.full_reward_spec, \"\\n\")\n",
    "print(\"done_spec:\\n\", env.full_done_spec, \"\\n\")\n",
    "print(\"observation_spec:\\n\", env.observation_spec, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_keys: [('agents', 'action')]\n",
      "reward_keys: [('agents', 'reward')]\n",
      "done_keys: ['done', 'terminated']\n"
     ]
    }
   ],
   "source": [
    "print(\"action_keys:\", env.action_keys)\n",
    "print(\"reward_keys:\", env.reward_keys)\n",
    "print(\"done_keys:\", env.done_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "\tenv,\n",
    "\tRewardSum(in_keys=[env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apshenitsyn/miniconda3/envs/jax/lib/python3.10/site-packages/torchrl/envs/common.py:1105: DeprecationWarning: You are querying a non-trivial, single action_spec, i.e., there is only one action known by the environment but it is not named `'action'`. Currently, env.action_spec returns the leaf but for consistency with the setter, this will return the full spec instead (from v0.8 and on).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "policy_net = MultiAgentMLP(\n",
    "\tn_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
    "\tn_agent_outputs=env.action_spec.shape[-1],\n",
    "\tn_agents=num_agents,\n",
    "\tdevice=device,\n",
    "\tdepth=2,\n",
    "\tnum_cells=256,\n",
    "\tactivation_class=torch.nn.Tanh,\n",
    "\tshare_params=True, # Can be changed\n",
    "\tcentralized=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_module = TensorDictModule(\n",
    "\tpolicy_net,\n",
    "\tin_keys=[(\"agents\", \"observation\")],\n",
    "\tout_keys=[(\"agents\", \"param\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = ProbabilisticActor(\n",
    "\tmodule=policy_module,\n",
    "\tspec=env.action_spec,\n",
    "\tin_keys=[(\"agents\", \"param\")],\n",
    "\tout_keys=[env.action_key],\n",
    "\tdistribution_class=TanhDelta,\n",
    "\tdistribution_kwargs={\n",
    "\t\t\"low\": env.full_action_spec_unbatched[\"agents\", \"action\"].space.low,\n",
    "\t\t\"high\": env.full_action_spec_unbatched[\"agents\", \"action\"].space.high,\n",
    "\t},\n",
    "\treturn_log_prob=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_policy = TensorDictSequential(\n",
    "\tpolicy,\n",
    "\tAdditiveGaussianModule(\n",
    "\t\tspec=policy.spec,\n",
    "\t\tannealing_num_steps=total_frames // 2,\n",
    "\t\taction_key=(\"agents\", \"action\"),\n",
    "\t\tsigma_init=0.9,\n",
    "\t\tsigma_end=0.1,\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_module = TensorDictModule(\n",
    "\tlambda obs, action: torch.cat([obs, action], dim=-1),\n",
    "\tin_keys=[(\"agents\", \"observation\"), (\"agents\", \"action\")],\n",
    "\tout_keys=[(\"agents\", \"obs_action\")],\n",
    ")\n",
    "\n",
    "critic_net = MultiAgentMLP(\n",
    "\tn_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1] + env.full_action_spec[\"agents\", \"action\"].shape[-1],\n",
    "\tn_agent_outputs=1,\n",
    "\tn_agents=num_agents,\n",
    "\tdevice=device,\n",
    "\tdepth=2,\n",
    "\tnum_cells=256,\n",
    "\tactivation_class=torch.nn.Tanh,\n",
    "\tshare_params=True, # can be changed\n",
    "\tcentralized=True, # True for maddpg and false for iddpg\n",
    ")\n",
    "\n",
    "critic_module = TensorDictModule(\n",
    "\tmodule=critic_net,\n",
    "\tin_keys=[(\"agents\", \"obs_action\")],\n",
    "\tout_keys=[(\"agents\", \"state_action_value\")],\n",
    ")\n",
    "\n",
    "critic = TensorDictSequential(\n",
    "\tcat_module, critic_module,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "\tenv,\n",
    "\texploration_policy,\n",
    "\tdevice=device,\n",
    "\tstoring_device=device,\n",
    "\tframes_per_batch=frames_per_batch,\n",
    "\ttotal_frames=total_frames,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "\tstorage=LazyTensorStorage(\n",
    "\t\tmemory_size, device=device\n",
    "\t),\n",
    "\tsampler=RandomSampler(),\n",
    "\tbatch_size=train_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = DDPGLoss(\n",
    "\tactor_network=policy,\n",
    "\tvalue_network=critic,\n",
    "\tdelay_value=True,\n",
    "\tloss_function=\"l2\",\n",
    ")\n",
    "loss_module.set_keys(\n",
    "\tstate_action_value=(\"agents\", \"state_action_value\"),\n",
    "\treward=env.reward_key,\n",
    "\tdone=(\"agents\", \"done\"),\n",
    "\tterminated=(\"agents\", \"terminated\"),\n",
    ")\n",
    "loss_module.make_value_estimator(ValueEstimators.TD0, gamma=gamma)\n",
    "\n",
    "target_updater = SoftUpdate(loss_module, tau=polyak_tau)\n",
    "\n",
    "optimisers = {\n",
    "\t\"loss_actor\": torch.optim.Adam(loss_module.actor_network_params.flatten_keys().values(), lr=lr),\n",
    "\t\"loss_value\": torch.optim.Adam(loss_module.value_network_params.flatten_keys().values(), lr=lr),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch: TensorDictBase) -> TensorDictBase:\n",
    "\t\"\"\"\n",
    "\tIf the `(group, \"terminated\")` and `(group, \"done\")` keys are not present, create them by expanding\n",
    "\t`\"terminated\"` and `\"done\"`.\n",
    "\tThis is needed to present them with the same shape as the reward to the loss.\n",
    "\t\"\"\"\n",
    "\tkeys = list(batch.keys(True, True))\n",
    "\tgroup_shape = batch.get_item_shape(\"agents\")\n",
    "\tnested_done_key = (\"next\", \"agents\", \"done\")\n",
    "\tnested_terminated_key = (\"next\", \"agents\", \"terminated\")\n",
    "\tif nested_done_key not in keys:\n",
    "\t\tbatch.set(\n",
    "\t\t\tnested_done_key,\n",
    "\t\t\tbatch.get((\"next\", \"done\")).unsqueeze(-1).expand((*group_shape, 1)),\n",
    "\t\t)\n",
    "\tif nested_terminated_key not in keys:\n",
    "\t\tbatch.set(\n",
    "\t\t\tnested_terminated_key,\n",
    "\t\t\tbatch.get((\"next\", \"terminated\"))\n",
    "\t\t\t.unsqueeze(-1)\n",
    "\t\t\t.expand((*group_shape, 1)),\n",
    "\t\t)\n",
    "\treturn batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338c37aec2cf4806a6d287f3c63a3993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "episode_reward_mean = 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mapshenitsyn\u001b[0m (\u001b[33mapshenitsyn-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/apshenitsyn/ContMAPF/wandb/run-20250319_020554-h6iapmyy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/apshenitsyn-/myenv_xppo/runs/h6iapmyy' target=\"_blank\">MADDPG1_collision_2.0_goal_dist_log_0.01</a></strong> to <a href='https://wandb.ai/apshenitsyn-/myenv_xppo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/apshenitsyn-/myenv_xppo' target=\"_blank\">https://wandb.ai/apshenitsyn-/myenv_xppo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/apshenitsyn-/myenv_xppo/runs/h6iapmyy' target=\"_blank\">https://wandb.ai/apshenitsyn-/myenv_xppo/runs/h6iapmyy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apshenitsyn/miniconda3/envs/jax/lib/python3.10/site-packages/torchrl/envs/libs/jax_utils.py:65: DeprecationWarning: Calling from_dlpack with a DLPack tensor is deprecated. The argument to from_dlpack should be an array from another framework that implements the __dlpack__ protocol.\n",
      "  return jax_dlpack.from_dlpack(torch_dlpack.to_dlpack(value.contiguous()))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ep_rew_mean</td><td>▇▁▃▄████████████████████████████████████</td></tr><tr><td>grad_norm_actor</td><td>█▃▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>grad_norm_value</td><td>▆▂▂▄▅█▅█▇▅▄▇▆▅▆█▇▅▅▇▄▅▂▁▂▂▂▂▂▂▂▂▁▃▂▁▃▂▃▂</td></tr><tr><td>iter</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>loss_actor</td><td>▅▅██▇▆▇▆▇▅▅▅▅▅▄▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_value</td><td>▆█▆██▄▄▄▄▄▄▄▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ep_rew_mean</td><td>6.90189</td></tr><tr><td>grad_norm_actor</td><td>0.01787</td></tr><tr><td>grad_norm_value</td><td>0.12523</td></tr><tr><td>iter</td><td>99</td></tr><tr><td>loss_actor</td><td>-1.02232</td></tr><tr><td>loss_value</td><td>0.02058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MADDPG1_collision_2.0_goal_dist_log_0.01</strong> at: <a href='https://wandb.ai/apshenitsyn-/myenv_xppo/runs/h6iapmyy' target=\"_blank\">https://wandb.ai/apshenitsyn-/myenv_xppo/runs/h6iapmyy</a><br> View project at: <a href='https://wandb.ai/apshenitsyn-/myenv_xppo' target=\"_blank\">https://wandb.ai/apshenitsyn-/myenv_xppo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250319_020554-h6iapmyy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
    "\n",
    "wandb.init(\n",
    "\tproject=\"myenv_xppo\",\n",
    "\tconfig={\n",
    "\t\t\"width\": width,\n",
    "\t\t\"height\": height,\n",
    "\t\t\"obstacle_density\": obstacle_density,\n",
    "\t\t\"num_agents\": num_agents,\n",
    "\t\t\"grain_factor\": grain_factor,\n",
    "\t\t\"frames_per_batch\": frames_per_batch,\n",
    "\t\t\"n_iters\": n_iters,\n",
    "\t\t\"total_frames\": total_frames,\n",
    "\t\t\"n_optimiser_steps\": n_optimiser_steps,\n",
    "\t\t\"train_batch_size\": train_batch_size,\n",
    "\t\t\"lr\": lr,\n",
    "\t\t\"max_grad_norm\": max_grad_norm,\n",
    "\t\t\"gamma\": gamma,\n",
    "\t\t\"polyak_tau\": polyak_tau,\n",
    "\t},\n",
    "\tname=f\"MADDPG1_collision_2.0_goal_dist_log_0.01\"\n",
    ")\n",
    "\n",
    "# Training/collection iterations\n",
    "for iteration, batch in enumerate(collector):\n",
    "\tcurrent_frames = batch.numel()\n",
    "\tbatch = process_batch(batch)  # Util to expand done keys if needed\n",
    "\n",
    "\tdata_view = batch.reshape(-1) # This just affects the leading dimensions in batch_size of the tensordict\n",
    "\treplay_buffer.extend(data_view)\n",
    "\n",
    "\tfor _ in range(n_optimiser_steps):\n",
    "\t\tsubdata = replay_buffer.sample()\n",
    "\t\tloss_vals = loss_module(subdata)\n",
    "\n",
    "\t\tgrad_norms = {}\n",
    "\n",
    "\t\tfor loss_name in [\"loss_actor\", \"loss_value\"]:\n",
    "\t\t\tloss = loss_vals[loss_name]\n",
    "\t\t\toptimiser = optimisers[loss_name]\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\n",
    "\t\t\t# Optional\n",
    "\t\t\tparams = optimiser.param_groups[0][\"params\"]\n",
    "\t\t\tgrad_norm = torch.nn.utils.clip_grad_norm_(params, max_grad_norm)\n",
    "\t\t\tgrad_norms[loss_name] = grad_norm\n",
    "\n",
    "\t\t\toptimiser.step()\n",
    "\t\t\toptimiser.zero_grad()\n",
    "\n",
    "\t\twandb.log({\n",
    "\t\t\t\"loss_actor\": loss_vals[\"loss_actor\"].item(),\n",
    "\t\t\t\"loss_value\": loss_vals[\"loss_value\"].item(),\n",
    "\t\t\t\"grad_norm_actor\": grad_norms[\"loss_actor\"].item(),\n",
    "\t\t\t\"grad_norm_value\": grad_norms[\"loss_value\"].item(),\n",
    "\t\t})\n",
    "\n",
    "\t\t# Soft-update the target network\n",
    "\t\ttarget_updater.step()\n",
    "\n",
    "\t# Exploration sigma anneal update\n",
    "\texploration_policy[-1].step(current_frames)\n",
    "\n",
    "\tdone = batch.get((\"next\", \"done\"))[:, :, 0]\n",
    "\tepisode_reward_mean = batch.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
    "\n",
    "\twandb.log({\n",
    "\t\t\"ep_rew_mean\": episode_reward_mean,\n",
    "\t\t\"iter\": iteration,\n",
    "\t})\n",
    "\n",
    "\tpbar.set_description(f\"episode_reward_mean = {episode_reward_mean :.2f}\", refresh=False)\n",
    "\tpbar.update()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "хорошие сиды для теста: \n",
    "\n",
    "4 (1)\n",
    "\n",
    "5 (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apshenitsyn/miniconda3/envs/jax/lib/python3.10/site-packages/torchrl/envs/libs/jax_utils.py:65: DeprecationWarning: Calling from_dlpack with a DLPack tensor is deprecated. The argument to from_dlpack should be an array from another framework that implements the __dlpack__ protocol.\n",
      "  return jax_dlpack.from_dlpack(torch_dlpack.to_dlpack(value.contiguous()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(900, Array(900, dtype=int32, weak_type=True))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_state_from_envs(state, env_id):\n",
    "\tstate_data = {field.name: getattr(state, field.name)[env_id] for field in dataclasses.fields(state)}\n",
    "\treturn type(state)(**state_data)\n",
    "\n",
    "def rendering_callback(env, td):\n",
    "\tenv.state_seq.append(get_state_from_envs(env._state, 0))\n",
    "\n",
    "\n",
    "viz_env = Env(\n",
    "\t\twidth=width,\n",
    "\t\theight=height,\n",
    "\t\tobstacle_density=obstacle_density,\n",
    "\t\tnum_agents=num_agents,\n",
    "\t\tgrain_factor=grain_factor,\n",
    "\t\tcontact_force=500,\n",
    "\t\tcontact_margin=1e-3,\n",
    "\t\tdt=0.01,\n",
    "\t\tmax_steps=env.max_steps,\n",
    "\t\tframeskip=7,\n",
    "\t\tmax_obs=8,\n",
    ")\n",
    "\n",
    "viz_env = MyEnvWrapper(viz_env, device=device, batch_size=[2])\n",
    "viz_env.set_seed(5)\n",
    "\n",
    "viz_env = TransformedEnv(\n",
    "\tviz_env,\n",
    "\tRewardSum(in_keys=[viz_env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
    ")\n",
    "\n",
    "\n",
    "viz_env.state_seq = []\n",
    "\n",
    "with torch.no_grad():\n",
    "   with set_exploration_type(ExplorationType.DETERMINISTIC):\n",
    "\t   out = viz_env.rollout(\n",
    "\t\t   auto_reset=True,\n",
    "\t\t   max_steps=viz_env.max_steps + 1,\n",
    "\t\t   policy=exploration_policy,\n",
    "\t\t   callback=rendering_callback,\n",
    "\t\t   auto_cast_to_device=True,\n",
    "\t\t   break_when_any_done=True,\n",
    "\t   )\n",
    "\n",
    "len(viz_env.state_seq), viz_env.state_seq[-1].step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_env.render.renderer import SVG_Visualizer\n",
    "\n",
    "SVG_Visualizer(viz_env._env, viz_env.state_seq).save_svg(\"maddpg_example.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7285, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"observation\"][1, :, :, 2:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def rewards(self, agent_pos, landmark_pos, goal_dist):\n",
    "\t\"\"\"Assign rewards for all agents\"\"\"\n",
    "\n",
    "\tobjects = jnp.vstack((agent_pos, landmark_pos))\n",
    "\n",
    "\tdistances = jnp.linalg.norm(agent_pos[:, None, :] - objects[None, :, :], axis=-1)\n",
    "\n",
    "\tnearest_dists, nearest_ids = jax.lax.top_k(-distances, 2) # (num_agents, 2)\n",
    "\n",
    "\t# remove zeros (nearest is the agent itself) -> (num_agents)\n",
    "\tnearest_ids = nearest_ids[:, 1]\n",
    "\tnearest_dists = -nearest_dists[:, 1]\n",
    "\n",
    "\teffective_rad = jnp.where(nearest_ids < self.num_agents, 2 * self.agent_rad, self.agent_rad + self.landmark_rad)\n",
    "\n",
    "\tcollision = nearest_dists < (effective_rad * 1.05)\n",
    "\n",
    "\ton_goal = goal_dist < self.goal_rad\n",
    "\n",
    "\t# r = 10.0 * on_goal.astype(jnp.float32) - 0.001 * goal_dist - 1 * collision.astype(jnp.float32)\n",
    "\tr = collision.astype(jnp.float32)\n",
    "\t# r = on_goal.astype(jnp.float32)\n",
    "\t# r = 1.0 * on_goal.astype(jnp.float32) - 0.5 * collision.astype(jnp.float32)\n",
    "\t# r = 1.0 * on_goal.astype(jnp.float32) - 0.2 * collision.astype(jnp.float32)\n",
    "\treturn r.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_seq = []\n",
    "for state_ in viz_env.state_seq:\n",
    "\tgoal_dist = jnp.linalg.norm(state_.agent_pos - state_.goal_pos, axis=-1)\n",
    "\trewards_seq.append(rewards(viz_env._env, state_.agent_pos, state_.landmark_pos, goal_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([58, 58, 59, 59, 60, 60, 61, 61, 62, 62, 63, 63, 64, 64, 65, 65, 66,\n",
       "        66, 67, 67, 68, 68, 69, 69, 70, 70, 71, 71, 72, 72, 73, 73, 74, 74,\n",
       "        75, 75, 76, 76, 77, 77, 78, 78, 79, 79, 80, 80], dtype=int32),\n",
       " Array([0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4,\n",
       "        0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4, 0, 4,\n",
       "        0, 4], dtype=int32),\n",
       " Array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0], dtype=int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.stack(rewards_seq).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_seq[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(viz_env.state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 157, 5, 18])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"observation\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4722, -0.6458, -0.5506, -0.0432, -0.0594,  0.1023,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"observation\"][0, 27, 0, :] * env._env.window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([146, 146, 147, 147, 148, 148, 149, 149, 150, 150, 151, 151, 152,\n",
       "        152, 153, 153, 154, 154, 155, 155, 156, 156, 157, 157, 158, 158,\n",
       "        159, 159, 160, 160, 161, 161, 162, 162, 163, 163, 164, 164, 165,\n",
       "        165, 166, 166, 167, 167, 168, 168, 169, 169, 170, 170, 171, 171],      dtype=int32),\n",
       " Array([1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n",
       "        1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n",
       "        1, 4, 1, 4, 1, 4, 1, 4], dtype=int32),\n",
       " Array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.stack(rewards_seq).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(agent_pos=Array([[-0.24154969, -1.4732722 ],\n",
       "       [ 0.29230696, -0.15225264],\n",
       "       [-0.6070331 , -0.18168508],\n",
       "       [-1.6136379 ,  1.6489443 ],\n",
       "       [ 0.35022047, -0.39659575]], dtype=float32), agent_vel=Array([[ 1.16601214e-02,  3.88432704e-02],\n",
       "       [ 2.21877787e-02, -1.51411280e-01],\n",
       "       [ 1.05127799e-06,  1.34114870e-08],\n",
       "       [-7.12279528e-02, -3.31292972e-02],\n",
       "       [-1.03568904e-01,  9.79412422e-02]], dtype=float32), goal_pos=Array([[-0.5999999 , -1.8       ],\n",
       "       [ 1.        , -1.8       ],\n",
       "       [-0.5999999 , -0.19999999],\n",
       "       [-1.4       ,  1.8       ],\n",
       "       [-1.        ,  1.4000001 ]], dtype=float32), landmark_pos=Array([[-2.        ,  2.        ],\n",
       "       [-1.9200001 ,  2.        ],\n",
       "       [-1.8399999 ,  2.        ],\n",
       "       [-1.76      ,  2.        ],\n",
       "       [-1.6800001 ,  2.        ],\n",
       "       [-1.5999999 ,  2.        ],\n",
       "       [-1.52      ,  2.        ],\n",
       "       [-1.44      ,  2.        ],\n",
       "       [-1.3600001 ,  2.        ],\n",
       "       [-1.28      ,  2.        ],\n",
       "       [-1.2       ,  2.        ],\n",
       "       [-1.1199999 ,  2.        ],\n",
       "       [-1.04      ,  2.        ],\n",
       "       [-0.96000004,  2.        ],\n",
       "       [-0.88000005,  2.        ],\n",
       "       [-0.80000013,  2.        ],\n",
       "       [-0.72      ,  2.        ],\n",
       "       [-0.6399999 ,  2.        ],\n",
       "       [-0.56      ,  2.        ],\n",
       "       [-0.48000002,  2.        ],\n",
       "       [-0.4000001 ,  2.        ],\n",
       "       [-0.3200001 ,  2.        ],\n",
       "       [-0.24000001,  2.        ],\n",
       "       [-0.16000009,  2.        ],\n",
       "       [-0.07999998,  2.        ],\n",
       "       [ 0.        ,  2.        ],\n",
       "       [ 0.07999992,  2.        ],\n",
       "       [ 0.15999985,  2.        ],\n",
       "       [ 0.24000001,  2.        ],\n",
       "       [ 0.31999993,  2.        ],\n",
       "       [ 0.39999986,  2.        ],\n",
       "       [ 0.48000002,  2.        ],\n",
       "       [ 0.55999994,  2.        ],\n",
       "       [ 0.63999987,  2.        ],\n",
       "       [ 0.72      ,  2.        ],\n",
       "       [ 0.79999995,  2.        ],\n",
       "       [ 0.8799999 ,  2.        ],\n",
       "       [ 0.96000004,  2.        ],\n",
       "       [ 1.04      ,  2.        ],\n",
       "       [ 1.1199999 ,  2.        ],\n",
       "       [ 1.1999998 ,  2.        ],\n",
       "       [ 1.28      ,  2.        ],\n",
       "       [ 1.3599999 ,  2.        ],\n",
       "       [ 1.4399998 ,  2.        ],\n",
       "       [ 1.52      ,  2.        ],\n",
       "       [ 1.5999999 ,  2.        ],\n",
       "       [ 1.6799998 ,  2.        ],\n",
       "       [ 1.76      ,  2.        ],\n",
       "       [ 1.8399999 ,  2.        ],\n",
       "       [ 1.9199998 ,  2.        ],\n",
       "       [ 2.        ,  2.        ],\n",
       "       [ 2.        ,  1.9200001 ],\n",
       "       [ 2.        ,  1.8399999 ],\n",
       "       [ 2.        ,  1.76      ],\n",
       "       [ 2.        ,  1.6800001 ],\n",
       "       [ 2.        ,  1.5999999 ],\n",
       "       [ 2.        ,  1.52      ],\n",
       "       [ 2.        ,  1.44      ],\n",
       "       [ 2.        ,  1.3600001 ],\n",
       "       [ 2.        ,  1.28      ],\n",
       "       [ 2.        ,  1.2       ],\n",
       "       [ 2.        ,  1.1199999 ],\n",
       "       [ 2.        ,  1.04      ],\n",
       "       [ 2.        ,  0.96000004],\n",
       "       [ 2.        ,  0.88000005],\n",
       "       [ 2.        ,  0.80000013],\n",
       "       [ 2.        ,  0.72      ],\n",
       "       [ 2.        ,  0.6399999 ],\n",
       "       [ 2.        ,  0.56      ],\n",
       "       [ 2.        ,  0.48000002],\n",
       "       [ 2.        ,  0.4000001 ],\n",
       "       [ 2.        ,  0.3200001 ],\n",
       "       [ 2.        ,  0.24000001],\n",
       "       [ 2.        ,  0.16000009],\n",
       "       [ 2.        ,  0.07999998],\n",
       "       [ 2.        ,  0.        ],\n",
       "       [ 2.        , -0.07999992],\n",
       "       [ 2.        , -0.15999985],\n",
       "       [ 2.        , -0.24000001],\n",
       "       [ 2.        , -0.31999993],\n",
       "       [ 2.        , -0.39999986],\n",
       "       [ 2.        , -0.48000002],\n",
       "       [ 2.        , -0.55999994],\n",
       "       [ 2.        , -0.63999987],\n",
       "       [ 2.        , -0.72      ],\n",
       "       [ 2.        , -0.79999995],\n",
       "       [ 2.        , -0.8799999 ],\n",
       "       [ 2.        , -0.96000004],\n",
       "       [ 2.        , -1.04      ],\n",
       "       [ 2.        , -1.1199999 ],\n",
       "       [ 2.        , -1.1999998 ],\n",
       "       [ 2.        , -1.28      ],\n",
       "       [ 2.        , -1.3599999 ],\n",
       "       [ 2.        , -1.4399998 ],\n",
       "       [ 2.        , -1.52      ],\n",
       "       [ 2.        , -1.5999999 ],\n",
       "       [ 2.        , -1.6799998 ],\n",
       "       [ 2.        , -1.76      ],\n",
       "       [ 2.        , -1.8399999 ],\n",
       "       [ 2.        , -1.9199998 ],\n",
       "       [-2.        , -2.        ],\n",
       "       [-2.        , -1.9200001 ],\n",
       "       [-2.        , -1.8399999 ],\n",
       "       [-2.        , -1.76      ],\n",
       "       [-2.        , -1.6800001 ],\n",
       "       [-2.        , -1.5999999 ],\n",
       "       [-2.        , -1.52      ],\n",
       "       [-2.        , -1.44      ],\n",
       "       [-2.        , -1.3600001 ],\n",
       "       [-2.        , -1.28      ],\n",
       "       [-2.        , -1.2       ],\n",
       "       [-2.        , -1.1199999 ],\n",
       "       [-2.        , -1.04      ],\n",
       "       [-2.        , -0.96000004],\n",
       "       [-2.        , -0.88000005],\n",
       "       [-2.        , -0.80000013],\n",
       "       [-2.        , -0.72      ],\n",
       "       [-2.        , -0.6399999 ],\n",
       "       [-2.        , -0.56      ],\n",
       "       [-2.        , -0.48000002],\n",
       "       [-2.        , -0.4000001 ],\n",
       "       [-2.        , -0.3200001 ],\n",
       "       [-2.        , -0.24000001],\n",
       "       [-2.        , -0.16000009],\n",
       "       [-2.        , -0.07999998],\n",
       "       [-2.        ,  0.        ],\n",
       "       [-2.        ,  0.07999992],\n",
       "       [-2.        ,  0.15999985],\n",
       "       [-2.        ,  0.24000001],\n",
       "       [-2.        ,  0.31999993],\n",
       "       [-2.        ,  0.39999986],\n",
       "       [-2.        ,  0.48000002],\n",
       "       [-2.        ,  0.55999994],\n",
       "       [-2.        ,  0.63999987],\n",
       "       [-2.        ,  0.72      ],\n",
       "       [-2.        ,  0.79999995],\n",
       "       [-2.        ,  0.8799999 ],\n",
       "       [-2.        ,  0.96000004],\n",
       "       [-2.        ,  1.04      ],\n",
       "       [-2.        ,  1.1199999 ],\n",
       "       [-2.        ,  1.1999998 ],\n",
       "       [-2.        ,  1.28      ],\n",
       "       [-2.        ,  1.3599999 ],\n",
       "       [-2.        ,  1.4399998 ],\n",
       "       [-2.        ,  1.52      ],\n",
       "       [-2.        ,  1.5999999 ],\n",
       "       [-2.        ,  1.6799998 ],\n",
       "       [-2.        ,  1.76      ],\n",
       "       [-2.        ,  1.8399999 ],\n",
       "       [-2.        ,  1.9199998 ],\n",
       "       [ 2.        , -2.        ],\n",
       "       [ 1.9200001 , -2.        ],\n",
       "       [ 1.8399999 , -2.        ],\n",
       "       [ 1.76      , -2.        ],\n",
       "       [ 1.6800001 , -2.        ],\n",
       "       [ 1.5999999 , -2.        ],\n",
       "       [ 1.52      , -2.        ],\n",
       "       [ 1.44      , -2.        ],\n",
       "       [ 1.3600001 , -2.        ],\n",
       "       [ 1.28      , -2.        ],\n",
       "       [ 1.2       , -2.        ],\n",
       "       [ 1.1199999 , -2.        ],\n",
       "       [ 1.04      , -2.        ],\n",
       "       [ 0.96000004, -2.        ],\n",
       "       [ 0.88000005, -2.        ],\n",
       "       [ 0.80000013, -2.        ],\n",
       "       [ 0.72      , -2.        ],\n",
       "       [ 0.6399999 , -2.        ],\n",
       "       [ 0.56      , -2.        ],\n",
       "       [ 0.48000002, -2.        ],\n",
       "       [ 0.4000001 , -2.        ],\n",
       "       [ 0.3200001 , -2.        ],\n",
       "       [ 0.24000001, -2.        ],\n",
       "       [ 0.16000009, -2.        ],\n",
       "       [ 0.07999998, -2.        ],\n",
       "       [ 0.        , -2.        ],\n",
       "       [-0.07999992, -2.        ],\n",
       "       [-0.15999985, -2.        ],\n",
       "       [-0.24000001, -2.        ],\n",
       "       [-0.31999993, -2.        ],\n",
       "       [-0.39999986, -2.        ],\n",
       "       [-0.48000002, -2.        ],\n",
       "       [-0.55999994, -2.        ],\n",
       "       [-0.63999987, -2.        ],\n",
       "       [-0.72      , -2.        ],\n",
       "       [-0.79999995, -2.        ],\n",
       "       [-0.8799999 , -2.        ],\n",
       "       [-0.96000004, -2.        ],\n",
       "       [-1.04      , -2.        ],\n",
       "       [-1.1199999 , -2.        ],\n",
       "       [-1.1999998 , -2.        ],\n",
       "       [-1.28      , -2.        ],\n",
       "       [-1.3599999 , -2.        ],\n",
       "       [-1.4399998 , -2.        ],\n",
       "       [-1.52      , -2.        ],\n",
       "       [-1.5999999 , -2.        ],\n",
       "       [-1.6799998 , -2.        ],\n",
       "       [-1.76      , -2.        ],\n",
       "       [-1.8399999 , -2.        ],\n",
       "       [-1.9199998 , -2.        ]], dtype=float32), step=Array(147, dtype=int32, weak_type=True))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state_seq[146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_seq[146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ = env.state_seq[146]\n",
    "objects = jnp.vstack((state_.agent_pos, state_.landmark_pos))\n",
    "\n",
    "distances = jnp.linalg.norm(state_.agent_pos[:, None, :] - objects[None, :, :], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_dists, nearest_ids = jax.lax.top_k(-distances, 2) # (num_agents, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([183,   4,   1,  10,   1], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_ids[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.078125"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01 / env._env.agent_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.01004225, -0.01014116, -0.01172379, -0.01026562,  0.7889613 ],      dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- nearest_dists[:, 1] - (env._env.agent_rad + env._env.landmark_rad) * 1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.37683833, -0.9155774 ], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(env.state_seq[123].agent_pos[4, :] - env.state_seq[123].agent_pos[1, :]) / env._env.window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3944,  0.0025, -0.0430,  0.2532,  0.0570,  0.2532, -0.1430,  0.2532,\n",
       "         0.1570,  0.2532, -0.2430,  0.2532,  0.2570,  0.2532, -0.3430,  0.2532,\n",
       "         0.3570,  0.2532], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"observation\"][0, 0, 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.8263538 , -0.54345036],\n",
       "       [ 1.4484562 ,  1.0495648 ],\n",
       "       [ 0.6185359 , -1.3465694 ],\n",
       "       [ 0.6263411 , -0.8824417 ],\n",
       "       [-0.58231133,  0.66071725]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state_seq[381].agent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-2.        ,  2.        ],\n",
       "       [-1.9200001 ,  2.        ],\n",
       "       [-1.8399999 ,  2.        ],\n",
       "       [-1.76      ,  2.        ],\n",
       "       [-1.6800001 ,  2.        ],\n",
       "       [-1.5999999 ,  2.        ],\n",
       "       [-1.52      ,  2.        ],\n",
       "       [-1.44      ,  2.        ],\n",
       "       [-1.3600001 ,  2.        ],\n",
       "       [-1.28      ,  2.        ],\n",
       "       [-1.2       ,  2.        ],\n",
       "       [-1.1199999 ,  2.        ],\n",
       "       [-1.04      ,  2.        ],\n",
       "       [-0.96000004,  2.        ],\n",
       "       [-0.88000005,  2.        ],\n",
       "       [-0.80000013,  2.        ],\n",
       "       [-0.72      ,  2.        ],\n",
       "       [-0.6399999 ,  2.        ],\n",
       "       [-0.56      ,  2.        ],\n",
       "       [-0.48000002,  2.        ],\n",
       "       [-0.4000001 ,  2.        ],\n",
       "       [-0.3200001 ,  2.        ],\n",
       "       [-0.24000001,  2.        ],\n",
       "       [-0.16000009,  2.        ],\n",
       "       [-0.07999998,  2.        ],\n",
       "       [ 0.        ,  2.        ],\n",
       "       [ 0.07999992,  2.        ],\n",
       "       [ 0.15999985,  2.        ],\n",
       "       [ 0.24000001,  2.        ],\n",
       "       [ 0.31999993,  2.        ],\n",
       "       [ 0.39999986,  2.        ],\n",
       "       [ 0.48000002,  2.        ],\n",
       "       [ 0.55999994,  2.        ],\n",
       "       [ 0.63999987,  2.        ],\n",
       "       [ 0.72      ,  2.        ],\n",
       "       [ 0.79999995,  2.        ],\n",
       "       [ 0.8799999 ,  2.        ],\n",
       "       [ 0.96000004,  2.        ],\n",
       "       [ 1.04      ,  2.        ],\n",
       "       [ 1.1199999 ,  2.        ],\n",
       "       [ 1.1999998 ,  2.        ],\n",
       "       [ 1.28      ,  2.        ],\n",
       "       [ 1.3599999 ,  2.        ],\n",
       "       [ 1.4399998 ,  2.        ],\n",
       "       [ 1.52      ,  2.        ],\n",
       "       [ 1.5999999 ,  2.        ],\n",
       "       [ 1.6799998 ,  2.        ],\n",
       "       [ 1.76      ,  2.        ],\n",
       "       [ 1.8399999 ,  2.        ],\n",
       "       [ 1.9199998 ,  2.        ],\n",
       "       [ 2.        ,  2.        ],\n",
       "       [ 2.        ,  1.9200001 ],\n",
       "       [ 2.        ,  1.8399999 ],\n",
       "       [ 2.        ,  1.76      ],\n",
       "       [ 2.        ,  1.6800001 ],\n",
       "       [ 2.        ,  1.5999999 ],\n",
       "       [ 2.        ,  1.52      ],\n",
       "       [ 2.        ,  1.44      ],\n",
       "       [ 2.        ,  1.3600001 ],\n",
       "       [ 2.        ,  1.28      ],\n",
       "       [ 2.        ,  1.2       ],\n",
       "       [ 2.        ,  1.1199999 ],\n",
       "       [ 2.        ,  1.04      ],\n",
       "       [ 2.        ,  0.96000004],\n",
       "       [ 2.        ,  0.88000005],\n",
       "       [ 2.        ,  0.80000013],\n",
       "       [ 2.        ,  0.72      ],\n",
       "       [ 2.        ,  0.6399999 ],\n",
       "       [ 2.        ,  0.56      ],\n",
       "       [ 2.        ,  0.48000002],\n",
       "       [ 2.        ,  0.4000001 ],\n",
       "       [ 2.        ,  0.3200001 ],\n",
       "       [ 2.        ,  0.24000001],\n",
       "       [ 2.        ,  0.16000009],\n",
       "       [ 2.        ,  0.07999998],\n",
       "       [ 2.        ,  0.        ],\n",
       "       [ 2.        , -0.07999992],\n",
       "       [ 2.        , -0.15999985],\n",
       "       [ 2.        , -0.24000001],\n",
       "       [ 2.        , -0.31999993],\n",
       "       [ 2.        , -0.39999986],\n",
       "       [ 2.        , -0.48000002],\n",
       "       [ 2.        , -0.55999994],\n",
       "       [ 2.        , -0.63999987],\n",
       "       [ 2.        , -0.72      ],\n",
       "       [ 2.        , -0.79999995],\n",
       "       [ 2.        , -0.8799999 ],\n",
       "       [ 2.        , -0.96000004],\n",
       "       [ 2.        , -1.04      ],\n",
       "       [ 2.        , -1.1199999 ],\n",
       "       [ 2.        , -1.1999998 ],\n",
       "       [ 2.        , -1.28      ],\n",
       "       [ 2.        , -1.3599999 ],\n",
       "       [ 2.        , -1.4399998 ],\n",
       "       [ 2.        , -1.52      ],\n",
       "       [ 2.        , -1.5999999 ],\n",
       "       [ 2.        , -1.6799998 ],\n",
       "       [ 2.        , -1.76      ],\n",
       "       [ 2.        , -1.8399999 ],\n",
       "       [ 2.        , -1.9199998 ],\n",
       "       [-2.        , -2.        ],\n",
       "       [-2.        , -1.9200001 ],\n",
       "       [-2.        , -1.8399999 ],\n",
       "       [-2.        , -1.76      ],\n",
       "       [-2.        , -1.6800001 ],\n",
       "       [-2.        , -1.5999999 ],\n",
       "       [-2.        , -1.52      ],\n",
       "       [-2.        , -1.44      ],\n",
       "       [-2.        , -1.3600001 ],\n",
       "       [-2.        , -1.28      ],\n",
       "       [-2.        , -1.2       ],\n",
       "       [-2.        , -1.1199999 ],\n",
       "       [-2.        , -1.04      ],\n",
       "       [-2.        , -0.96000004],\n",
       "       [-2.        , -0.88000005],\n",
       "       [-2.        , -0.80000013],\n",
       "       [-2.        , -0.72      ],\n",
       "       [-2.        , -0.6399999 ],\n",
       "       [-2.        , -0.56      ],\n",
       "       [-2.        , -0.48000002],\n",
       "       [-2.        , -0.4000001 ],\n",
       "       [-2.        , -0.3200001 ],\n",
       "       [-2.        , -0.24000001],\n",
       "       [-2.        , -0.16000009],\n",
       "       [-2.        , -0.07999998],\n",
       "       [-2.        ,  0.        ],\n",
       "       [-2.        ,  0.07999992],\n",
       "       [-2.        ,  0.15999985],\n",
       "       [-2.        ,  0.24000001],\n",
       "       [-2.        ,  0.31999993],\n",
       "       [-2.        ,  0.39999986],\n",
       "       [-2.        ,  0.48000002],\n",
       "       [-2.        ,  0.55999994],\n",
       "       [-2.        ,  0.63999987],\n",
       "       [-2.        ,  0.72      ],\n",
       "       [-2.        ,  0.79999995],\n",
       "       [-2.        ,  0.8799999 ],\n",
       "       [-2.        ,  0.96000004],\n",
       "       [-2.        ,  1.04      ],\n",
       "       [-2.        ,  1.1199999 ],\n",
       "       [-2.        ,  1.1999998 ],\n",
       "       [-2.        ,  1.28      ],\n",
       "       [-2.        ,  1.3599999 ],\n",
       "       [-2.        ,  1.4399998 ],\n",
       "       [-2.        ,  1.52      ],\n",
       "       [-2.        ,  1.5999999 ],\n",
       "       [-2.        ,  1.6799998 ],\n",
       "       [-2.        ,  1.76      ],\n",
       "       [-2.        ,  1.8399999 ],\n",
       "       [-2.        ,  1.9199998 ],\n",
       "       [ 2.        , -2.        ],\n",
       "       [ 1.9200001 , -2.        ],\n",
       "       [ 1.8399999 , -2.        ],\n",
       "       [ 1.76      , -2.        ],\n",
       "       [ 1.6800001 , -2.        ],\n",
       "       [ 1.5999999 , -2.        ],\n",
       "       [ 1.52      , -2.        ],\n",
       "       [ 1.44      , -2.        ],\n",
       "       [ 1.3600001 , -2.        ],\n",
       "       [ 1.28      , -2.        ],\n",
       "       [ 1.2       , -2.        ],\n",
       "       [ 1.1199999 , -2.        ],\n",
       "       [ 1.04      , -2.        ],\n",
       "       [ 0.96000004, -2.        ],\n",
       "       [ 0.88000005, -2.        ],\n",
       "       [ 0.80000013, -2.        ],\n",
       "       [ 0.72      , -2.        ],\n",
       "       [ 0.6399999 , -2.        ],\n",
       "       [ 0.56      , -2.        ],\n",
       "       [ 0.48000002, -2.        ],\n",
       "       [ 0.4000001 , -2.        ],\n",
       "       [ 0.3200001 , -2.        ],\n",
       "       [ 0.24000001, -2.        ],\n",
       "       [ 0.16000009, -2.        ],\n",
       "       [ 0.07999998, -2.        ],\n",
       "       [ 0.        , -2.        ],\n",
       "       [-0.07999992, -2.        ],\n",
       "       [-0.15999985, -2.        ],\n",
       "       [-0.24000001, -2.        ],\n",
       "       [-0.31999993, -2.        ],\n",
       "       [-0.39999986, -2.        ],\n",
       "       [-0.48000002, -2.        ],\n",
       "       [-0.55999994, -2.        ],\n",
       "       [-0.63999987, -2.        ],\n",
       "       [-0.72      , -2.        ],\n",
       "       [-0.79999995, -2.        ],\n",
       "       [-0.8799999 , -2.        ],\n",
       "       [-0.96000004, -2.        ],\n",
       "       [-1.04      , -2.        ],\n",
       "       [-1.1199999 , -2.        ],\n",
       "       [-1.1999998 , -2.        ],\n",
       "       [-1.28      , -2.        ],\n",
       "       [-1.3599999 , -2.        ],\n",
       "       [-1.4399998 , -2.        ],\n",
       "       [-1.52      , -2.        ],\n",
       "       [-1.5999999 , -2.        ],\n",
       "       [-1.6799998 , -2.        ],\n",
       "       [-1.76      , -2.        ],\n",
       "       [-1.8399999 , -2.        ],\n",
       "       [-1.9199998 , -2.        ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state_seq[381].landmark_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9973,  2.7944,  0.7533,  0.0430,  0.7533, -0.0570,  0.7533,  0.1430,\n",
       "         0.7533, -0.1570,  0.7533,  0.2430,  0.7533, -0.2570,  0.7533,  0.3430,\n",
       "         0.7533, -0.3570], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_id = 0\n",
    "out[\"next\", \"agents\", \"observation\"][0, 0, agent_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.3973355 , -0.99443763],\n",
       "       [-1.7930828 , -0.1948089 ],\n",
       "       [-1.4070048 ,  1.7959106 ],\n",
       "       [-0.1949299 , -0.5935761 ],\n",
       "       [ 0.5929402 , -0.60317606]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state_seq[0].agent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9302e-03, -7.7401e-03, -1.1426e-02, -1.4990e-02, -1.8433e-02,\n",
       "        -2.1754e-02, -2.4954e-02, -2.8036e-02, -3.1001e-02, -3.3852e-02,\n",
       "        -3.6590e-02, -3.9212e-02, -4.1716e-02, -4.4100e-02, -4.6370e-02,\n",
       "        -4.8530e-02, -5.0574e-02, -5.2499e-02, -5.4303e-02, -5.5999e-02,\n",
       "        -5.7591e-02, -5.9075e-02, -6.0465e-02, -6.1768e-02, -6.2964e-02,\n",
       "        -6.4053e-02, -6.5035e-02, -6.5901e-02, -6.6642e-02, -6.7256e-02,\n",
       "        -6.7751e-02,  9.3186e-01,  1.9316e+00,  2.9313e+00,  3.9311e+00,\n",
       "         4.9310e+00,  5.9309e+00,  6.9308e+00,  7.9308e+00,  8.9306e+00,\n",
       "         9.9304e+00,  1.0930e+01,  1.1930e+01,  1.2930e+01,  1.3930e+01,\n",
       "         1.4929e+01,  1.5929e+01,  1.6929e+01,  1.7929e+01,  1.8928e+01,\n",
       "         1.9928e+01,  2.0928e+01,  2.1928e+01,  2.2928e+01,  2.3927e+01,\n",
       "         2.4927e+01,  2.5927e+01,  2.6927e+01,  2.7927e+01,  2.8927e+01,\n",
       "         2.9927e+01,  3.0926e+01,  3.1926e+01,  3.2926e+01,  3.3926e+01,\n",
       "         3.4926e+01,  3.5926e+01,  3.6926e+01,  3.7925e+01,  3.8925e+01,\n",
       "         3.9925e+01,  4.0925e+01,  4.1925e+01,  4.2924e+01,  4.3924e+01,\n",
       "         4.4924e+01,  4.5924e+01,  4.6923e+01,  4.7923e+01,  4.8923e+01,\n",
       "         4.9923e+01,  5.0922e+01,  5.1922e+01,  5.2922e+01,  5.3922e+01,\n",
       "         5.4922e+01,  5.5921e+01,  5.6921e+01,  5.7921e+01,  5.8921e+01,\n",
       "         5.9920e+01,  6.0920e+01,  6.1920e+01,  6.2920e+01,  6.3920e+01,\n",
       "         6.4920e+01,  6.5919e+01,  6.6919e+01,  6.7919e+01,  6.8919e+01,\n",
       "         6.9919e+01,  7.0919e+01,  7.1919e+01,  7.2919e+01,  7.3919e+01,\n",
       "         7.4918e+01,  7.5918e+01,  7.6918e+01,  7.7918e+01,  7.8917e+01,\n",
       "         7.9917e+01,  8.0917e+01,  8.1917e+01,  8.2917e+01,  8.3916e+01,\n",
       "         8.4916e+01,  8.5916e+01,  8.6916e+01,  8.7915e+01,  8.8915e+01,\n",
       "         8.9915e+01,  9.0915e+01,  9.1914e+01,  9.2914e+01,  9.3914e+01,\n",
       "         9.4914e+01,  9.5914e+01,  9.6913e+01,  9.7913e+01,  9.8913e+01,\n",
       "         9.9913e+01,  1.0091e+02,  1.0191e+02,  1.0291e+02,  1.0391e+02,\n",
       "         1.0491e+02,  1.0591e+02,  1.0691e+02,  1.0791e+02,  1.0891e+02,\n",
       "         1.0991e+02,  1.1091e+02,  1.1191e+02,  1.1291e+02,  1.1391e+02,\n",
       "         1.1491e+02,  1.1591e+02,  1.1691e+02,  1.1791e+02,  1.1891e+02,\n",
       "         1.1991e+02,  1.2091e+02,  1.2191e+02,  1.2291e+02,  1.2391e+02,\n",
       "         1.2491e+02,  1.2591e+02,  1.2691e+02,  1.2791e+02,  1.2891e+02,\n",
       "         1.2991e+02,  1.3091e+02,  1.3191e+02,  1.3291e+02,  1.3391e+02,\n",
       "         1.3491e+02,  1.3591e+02,  1.3691e+02,  1.3791e+02,  1.3891e+02,\n",
       "         1.3991e+02,  1.4090e+02,  1.4190e+02,  1.4290e+02,  1.4390e+02,\n",
       "         1.4490e+02,  1.4590e+02,  1.4690e+02,  1.4790e+02,  1.4890e+02,\n",
       "         1.4990e+02,  1.5090e+02,  1.5190e+02,  1.5290e+02,  1.5390e+02,\n",
       "         1.5490e+02,  1.5590e+02,  1.5690e+02,  1.5790e+02,  1.5890e+02,\n",
       "         1.5990e+02,  1.6090e+02,  1.6190e+02,  1.6290e+02,  1.6390e+02,\n",
       "         1.6490e+02,  1.6590e+02,  1.6690e+02,  1.6790e+02,  1.6890e+02,\n",
       "         1.6990e+02,  1.7090e+02,  1.7190e+02,  1.7290e+02,  1.7390e+02,\n",
       "         1.7490e+02,  1.7590e+02,  1.7690e+02,  1.7790e+02,  1.7890e+02,\n",
       "         1.7990e+02,  1.8090e+02,  1.8190e+02,  1.8290e+02,  1.8390e+02,\n",
       "         1.8490e+02,  1.8590e+02,  1.8690e+02,  1.8790e+02,  1.8890e+02,\n",
       "         1.8990e+02,  1.9090e+02,  1.9190e+02,  1.9290e+02,  1.9390e+02,\n",
       "         1.9490e+02,  1.9589e+02,  1.9689e+02,  1.9789e+02,  1.9889e+02,\n",
       "         1.9989e+02,  2.0089e+02,  2.0189e+02,  2.0289e+02,  2.0389e+02,\n",
       "         2.0489e+02,  2.0589e+02,  2.0689e+02,  2.0789e+02,  2.0889e+02,\n",
       "         2.0989e+02,  2.1089e+02,  2.1189e+02,  2.1289e+02,  2.1389e+02,\n",
       "         2.1489e+02,  2.1589e+02,  2.1689e+02,  2.1789e+02,  2.1889e+02,\n",
       "         2.1989e+02,  2.2089e+02,  2.2189e+02,  2.2289e+02,  2.2389e+02,\n",
       "         2.2489e+02,  2.2589e+02,  2.2689e+02,  2.2789e+02,  2.2889e+02,\n",
       "         2.2989e+02,  2.3089e+02,  2.3189e+02,  2.3289e+02,  2.3389e+02,\n",
       "         2.3489e+02,  2.3589e+02,  2.3689e+02,  2.3789e+02,  2.3889e+02,\n",
       "         2.3989e+02,  2.4089e+02,  2.4189e+02,  2.4289e+02,  2.4389e+02,\n",
       "         2.4489e+02,  2.4588e+02,  2.4688e+02,  2.4788e+02,  2.4888e+02,\n",
       "         2.4988e+02,  2.5088e+02,  2.5188e+02,  2.5288e+02,  2.5388e+02,\n",
       "         2.5488e+02,  2.5588e+02,  2.5688e+02,  2.5788e+02,  2.5888e+02,\n",
       "         2.5988e+02,  2.6088e+02,  2.6188e+02,  2.6288e+02,  2.6388e+02,\n",
       "         2.6488e+02,  2.6588e+02,  2.6688e+02,  2.6788e+02,  2.6888e+02,\n",
       "         2.6988e+02,  2.7088e+02,  2.7188e+02,  2.7288e+02,  2.7388e+02,\n",
       "         2.7488e+02,  2.7588e+02,  2.7688e+02,  2.7788e+02,  2.7888e+02,\n",
       "         2.7988e+02,  2.8088e+02,  2.8188e+02,  2.8288e+02,  2.8388e+02,\n",
       "         2.8488e+02,  2.8588e+02,  2.8688e+02,  2.8788e+02,  2.8888e+02,\n",
       "         2.8988e+02,  2.9088e+02,  2.9188e+02,  2.9288e+02,  2.9388e+02,\n",
       "         2.9488e+02,  2.9588e+02,  2.9688e+02,  2.9788e+02,  2.9888e+02,\n",
       "         2.9988e+02,  3.0088e+02,  3.0188e+02,  3.0288e+02,  3.0388e+02,\n",
       "         3.0487e+02,  3.0587e+02,  3.0687e+02,  3.0787e+02,  3.0887e+02,\n",
       "         3.0987e+02,  3.1087e+02,  3.1187e+02,  3.1287e+02,  3.1387e+02,\n",
       "         3.1487e+02,  3.1587e+02,  3.1687e+02,  3.1787e+02,  3.1887e+02,\n",
       "         3.1987e+02,  3.2087e+02,  3.2187e+02,  3.2287e+02,  3.2387e+02,\n",
       "         3.2487e+02,  3.2587e+02,  3.2687e+02,  3.2787e+02,  3.2887e+02,\n",
       "         3.2987e+02,  3.3087e+02,  3.3187e+02,  3.3287e+02,  3.3387e+02,\n",
       "         3.3487e+02,  3.3587e+02,  3.3687e+02,  3.3787e+02,  3.3887e+02,\n",
       "         3.3987e+02,  3.4087e+02,  3.4187e+02,  3.4287e+02,  3.4387e+02,\n",
       "         3.4487e+02,  3.4587e+02,  3.4687e+02,  3.4787e+02,  3.4887e+02,\n",
       "         3.4987e+02,  3.5087e+02,  3.5187e+02,  3.5287e+02,  3.5387e+02,\n",
       "         3.5487e+02,  3.5587e+02,  3.5687e+02,  3.5787e+02,  3.5887e+02,\n",
       "         3.5987e+02,  3.6086e+02,  3.6186e+02,  3.6286e+02,  3.6386e+02,\n",
       "         3.6486e+02,  3.6586e+02,  3.6686e+02,  3.6786e+02,  3.6886e+02,\n",
       "         3.6986e+02,  3.7086e+02,  3.7186e+02,  3.7286e+02,  3.7386e+02,\n",
       "         3.7486e+02,  3.7586e+02,  3.7686e+02,  3.7786e+02,  3.7886e+02,\n",
       "         3.7986e+02,  3.8086e+02,  3.8186e+02,  3.8286e+02,  3.8386e+02,\n",
       "         3.8486e+02,  3.8586e+02,  3.8686e+02,  3.8786e+02,  3.8886e+02,\n",
       "         3.8986e+02,  3.9086e+02,  3.9186e+02,  3.9286e+02,  3.9386e+02,\n",
       "         3.9486e+02,  3.9586e+02,  3.9686e+02,  3.9786e+02,  3.9886e+02,\n",
       "         3.9986e+02,  4.0086e+02,  4.0186e+02,  4.0286e+02,  4.0386e+02,\n",
       "         4.0486e+02,  4.0586e+02,  4.0686e+02,  4.0786e+02,  4.0886e+02,\n",
       "         4.0986e+02,  4.1085e+02,  4.1185e+02,  4.1285e+02,  4.1385e+02,\n",
       "         4.1485e+02,  4.1585e+02,  4.1685e+02,  4.1785e+02,  4.1885e+02,\n",
       "         4.1985e+02,  4.2085e+02,  4.2185e+02,  4.2285e+02,  4.2385e+02,\n",
       "         4.2485e+02,  4.2585e+02,  4.2685e+02,  4.2785e+02,  4.2885e+02,\n",
       "         4.2985e+02,  4.3085e+02,  4.3185e+02,  4.3285e+02,  4.3385e+02,\n",
       "         4.3485e+02,  4.3585e+02,  4.3685e+02,  4.3785e+02,  4.3885e+02,\n",
       "         4.3985e+02,  4.4085e+02,  4.4185e+02,  4.4285e+02,  4.4385e+02,\n",
       "         4.4485e+02,  4.4585e+02,  4.4685e+02,  4.4785e+02,  4.4885e+02,\n",
       "         4.4985e+02,  4.5085e+02,  4.5185e+02,  4.5285e+02,  4.5385e+02,\n",
       "         4.5485e+02,  4.5585e+02,  4.5685e+02,  4.5785e+02,  4.5885e+02,\n",
       "         4.5985e+02,  4.6085e+02,  4.6185e+02,  4.6285e+02,  4.6385e+02,\n",
       "         4.6485e+02,  4.6584e+02,  4.6684e+02,  4.6784e+02,  4.6884e+02,\n",
       "         4.6984e+02,  4.7084e+02,  4.7184e+02,  4.7284e+02,  4.7384e+02,\n",
       "         4.7484e+02,  4.7584e+02,  4.7684e+02,  4.7784e+02,  4.7884e+02,\n",
       "         4.7984e+02,  4.8084e+02,  4.8184e+02,  4.8284e+02,  4.8384e+02,\n",
       "         4.8484e+02,  4.8584e+02,  4.8684e+02,  4.8784e+02,  4.8884e+02,\n",
       "         4.8984e+02,  4.9084e+02,  4.9184e+02,  4.9284e+02,  4.9384e+02,\n",
       "         4.9484e+02,  4.9584e+02,  4.9684e+02,  4.9784e+02,  4.9884e+02,\n",
       "         4.9984e+02,  5.0084e+02,  5.0184e+02,  5.0284e+02,  5.0384e+02,\n",
       "         5.0484e+02,  5.0584e+02,  5.0684e+02,  5.0784e+02,  5.0884e+02,\n",
       "         5.0984e+02,  5.1084e+02,  5.1184e+02,  5.1284e+02,  5.1384e+02,\n",
       "         5.1483e+02,  5.1583e+02,  5.1683e+02,  5.1783e+02,  5.1883e+02,\n",
       "         5.1983e+02,  5.2083e+02,  5.2183e+02,  5.2283e+02,  5.2383e+02,\n",
       "         5.2483e+02,  5.2583e+02,  5.2683e+02,  5.2783e+02,  5.2883e+02,\n",
       "         5.2983e+02,  5.3083e+02,  5.3183e+02,  5.3283e+02,  5.3383e+02,\n",
       "         5.3483e+02,  5.3583e+02,  5.3683e+02,  5.3783e+02,  5.3883e+02,\n",
       "         5.3983e+02,  5.4083e+02,  5.4183e+02,  5.4283e+02,  5.4383e+02,\n",
       "         5.4483e+02,  5.4583e+02,  5.4683e+02,  5.4783e+02,  5.4883e+02,\n",
       "         5.4983e+02,  5.5083e+02,  5.5183e+02,  5.5283e+02,  5.5383e+02,\n",
       "         5.5483e+02,  5.5583e+02,  5.5683e+02,  5.5783e+02,  5.5883e+02,\n",
       "         5.5983e+02,  5.6083e+02,  5.6183e+02,  5.6283e+02,  5.6383e+02,\n",
       "         5.6483e+02,  5.6583e+02,  5.6683e+02,  5.6783e+02,  5.6883e+02,\n",
       "         5.6983e+02,  5.7083e+02,  5.7183e+02,  5.7282e+02,  5.7382e+02,\n",
       "         5.7482e+02,  5.7582e+02,  5.7682e+02,  5.7782e+02,  5.7882e+02,\n",
       "         5.7982e+02,  5.8082e+02,  5.8182e+02,  5.8282e+02,  5.8382e+02,\n",
       "         5.8482e+02,  5.8582e+02,  5.8682e+02,  5.8782e+02,  5.8882e+02,\n",
       "         5.8982e+02,  5.9082e+02,  5.9182e+02,  5.9282e+02,  5.9382e+02,\n",
       "         5.9482e+02,  5.9582e+02,  5.9682e+02,  5.9782e+02,  5.9882e+02,\n",
       "         5.9982e+02,  6.0082e+02,  6.0182e+02,  6.0282e+02,  6.0382e+02,\n",
       "         6.0482e+02,  6.0582e+02,  6.0682e+02,  6.0782e+02,  6.0882e+02,\n",
       "         6.0982e+02,  6.1082e+02,  6.1182e+02,  6.1282e+02,  6.1382e+02,\n",
       "         6.1482e+02,  6.1582e+02,  6.1682e+02,  6.1782e+02,  6.1882e+02,\n",
       "         6.1982e+02,  6.2082e+02,  6.2182e+02,  6.2282e+02,  6.2382e+02,\n",
       "         6.2482e+02,  6.2582e+02,  6.2682e+02,  6.2781e+02,  6.2881e+02,\n",
       "         6.2981e+02,  6.3081e+02,  6.3181e+02,  6.3281e+02,  6.3381e+02,\n",
       "         6.3481e+02,  6.3581e+02,  6.3681e+02,  6.3781e+02,  6.3881e+02,\n",
       "         6.3981e+02,  6.4081e+02,  6.4181e+02,  6.4281e+02,  6.4381e+02,\n",
       "         6.4481e+02,  6.4581e+02,  6.4681e+02,  6.4781e+02,  6.4881e+02,\n",
       "         6.4981e+02,  6.5081e+02,  6.5181e+02,  6.5281e+02,  6.5381e+02,\n",
       "         6.5481e+02,  6.5581e+02,  6.5681e+02,  6.5781e+02,  6.5881e+02,\n",
       "         6.5981e+02,  6.6081e+02,  6.6181e+02,  6.6281e+02,  6.6381e+02,\n",
       "         6.6481e+02,  6.6581e+02,  6.6681e+02,  6.6781e+02,  6.6881e+02,\n",
       "         6.6981e+02,  6.7081e+02,  6.7181e+02,  6.7281e+02,  6.7381e+02,\n",
       "         6.7481e+02,  6.7581e+02,  6.7681e+02,  6.7781e+02,  6.7881e+02,\n",
       "         6.7980e+02,  6.8080e+02,  6.8180e+02,  6.8280e+02,  6.8380e+02,\n",
       "         6.8480e+02,  6.8580e+02,  6.8680e+02,  6.8780e+02,  6.8880e+02,\n",
       "         6.8980e+02,  6.9080e+02,  6.9180e+02,  6.9280e+02,  6.9380e+02,\n",
       "         6.9480e+02,  6.9580e+02,  6.9680e+02,  6.9780e+02,  6.9880e+02,\n",
       "         6.9980e+02,  7.0080e+02,  7.0180e+02,  7.0280e+02,  7.0380e+02,\n",
       "         7.0480e+02,  7.0580e+02,  7.0680e+02,  7.0780e+02,  7.0880e+02,\n",
       "         7.0980e+02,  7.1080e+02,  7.1180e+02,  7.1280e+02,  7.1380e+02,\n",
       "         7.1480e+02,  7.1580e+02,  7.1680e+02,  7.1780e+02,  7.1880e+02,\n",
       "         7.1980e+02,  7.2080e+02,  7.2180e+02,  7.2280e+02,  7.2380e+02,\n",
       "         7.2480e+02,  7.2580e+02,  7.2680e+02,  7.2780e+02,  7.2880e+02,\n",
       "         7.2980e+02,  7.3080e+02,  7.3180e+02,  7.3280e+02,  7.3380e+02,\n",
       "         7.3480e+02,  7.3580e+02,  7.3679e+02,  7.3779e+02,  7.3879e+02,\n",
       "         7.3979e+02,  7.4079e+02,  7.4179e+02,  7.4279e+02,  7.4379e+02,\n",
       "         7.4479e+02,  7.4579e+02,  7.4679e+02,  7.4779e+02,  7.4879e+02,\n",
       "         7.4979e+02,  7.5079e+02,  7.5179e+02,  7.5279e+02,  7.5379e+02,\n",
       "         7.5479e+02,  7.5579e+02,  7.5679e+02,  7.5779e+02,  7.5879e+02,\n",
       "         7.5979e+02,  7.6079e+02,  7.6179e+02,  7.6279e+02,  7.6379e+02,\n",
       "         7.6479e+02,  7.6579e+02,  7.6679e+02,  7.6779e+02,  7.6879e+02,\n",
       "         7.6979e+02,  7.7079e+02,  7.7179e+02,  7.7279e+02,  7.7379e+02,\n",
       "         7.7479e+02,  7.7579e+02,  7.7679e+02,  7.7779e+02,  7.7879e+02,\n",
       "         7.7979e+02,  7.8079e+02,  7.8179e+02,  7.8279e+02,  7.8379e+02,\n",
       "         7.8478e+02,  7.8578e+02,  7.8678e+02,  7.8778e+02,  7.8878e+02,\n",
       "         7.8978e+02,  7.9078e+02,  7.9178e+02,  7.9278e+02,  7.9378e+02,\n",
       "         7.9478e+02,  7.9578e+02,  7.9678e+02,  7.9778e+02,  7.9878e+02,\n",
       "         7.9978e+02,  8.0078e+02,  8.0178e+02,  8.0278e+02,  8.0378e+02,\n",
       "         8.0478e+02,  8.0578e+02,  8.0678e+02,  8.0778e+02,  8.0878e+02,\n",
       "         8.0978e+02,  8.1078e+02,  8.1178e+02,  8.1278e+02,  8.1378e+02,\n",
       "         8.1478e+02,  8.1578e+02,  8.1678e+02,  8.1778e+02,  8.1878e+02,\n",
       "         8.1978e+02,  8.2078e+02,  8.2178e+02,  8.2278e+02,  8.2378e+02,\n",
       "         8.2478e+02,  8.2578e+02,  8.2678e+02,  8.2778e+02,  8.2878e+02,\n",
       "         8.2978e+02,  8.3078e+02,  8.3178e+02,  8.3278e+02,  8.3378e+02,\n",
       "         8.3478e+02,  8.3578e+02,  8.3678e+02,  8.3778e+02,  8.3878e+02,\n",
       "         8.3978e+02,  8.4078e+02,  8.4178e+02,  8.4277e+02,  8.4377e+02,\n",
       "         8.4477e+02,  8.4577e+02,  8.4677e+02,  8.4777e+02,  8.4877e+02,\n",
       "         8.4977e+02,  8.5077e+02,  8.5177e+02,  8.5277e+02,  8.5377e+02,\n",
       "         8.5477e+02,  8.5577e+02,  8.5677e+02,  8.5777e+02,  8.5877e+02,\n",
       "         8.5977e+02,  8.6077e+02,  8.6177e+02,  8.6277e+02,  8.6377e+02,\n",
       "         8.6477e+02,  8.6577e+02,  8.6677e+02,  8.6777e+02,  8.6877e+02],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"episode_reward\"][0, :, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 900, 5, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"reward\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5092,  1.5685,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"observation\"][0, 122, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-0.0021, -0.0084,  0.9999,  0.9998,  0.9998], device='cuda:0'),\n",
       "indices=tensor([310, 744, 364, 124, 146], device='cuda:0'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"reward\"][0, :, :, 0].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1659, -0.6391], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"agents\", \"action\"][0][-3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2785,  0.1100, -0.0019,  0.3875,  0.0981,  0.3875, -0.1019,  0.3875,\n",
       "          0.1981,  0.3875, -0.2019,  0.3875,  0.2981,  0.3875, -0.3019,  0.3875,\n",
       "          0.3981,  0.3875],\n",
       "        [ 0.7557,  0.3890, -0.0054,  0.7363,  0.0946,  0.7363, -0.1054,  0.7363,\n",
       "          0.1946,  0.7363, -0.2054,  0.7363,  0.2946,  0.7363, -0.3054,  0.7363,\n",
       "          0.3946,  0.7363],\n",
       "        [ 0.0100,  0.0054, -0.2375, -0.0432, -0.2375,  0.0568, -0.0375,  0.2568,\n",
       "          0.0625,  0.2568, -0.2375, -0.1432, -0.2375,  0.1568, -0.1375,  0.2568,\n",
       "          0.1625,  0.2568],\n",
       "        [ 0.0115, -0.0155,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0115, -0.0155,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"next\", \"agents\", \"observation\"][0][-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 18)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env = Grid_Maze(\n",
    "\t\twidth=width,\n",
    "\t\theight=height,\n",
    "\t\tobstacle_density=obstacle_density,\n",
    "\t\tnum_agents=num_agents,\n",
    "\t\tgrain_factor=grain_factor,\n",
    "\t\tcontact_force=500,\n",
    "\t\tcontact_margin=1e-3,\n",
    "\t\tdt=0.01,\n",
    "\t\tmax_steps=300,\n",
    "\t\tframeskip=7,\n",
    "\t\tmax_obs=env._env.max_obs,\n",
    ")\n",
    "\n",
    "last_state = env.state_seq[-1]\n",
    "obs = test_env.get_obs(last_state.agent_pos, last_state.landmark_pos, last_state.goal_pos)\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.2809835 ,  0.11932576,  0.0012292 ,  0.39915726, -0.09877078,\n",
       "         0.39915726,  0.1012291 ,  0.39915726, -0.19877069,  0.39915726,\n",
       "         0.20122923,  0.39915726, -0.2987706 ,  0.39915726,  0.30122936,\n",
       "         0.39915726, -0.3987708 ,  0.39915726],\n",
       "       [ 0.7566569 ,  0.38993514, -0.00417918,  0.737419  ,  0.09582102,\n",
       "         0.737419  , -0.10417908,  0.737419  ,  0.19582093,  0.737419  ,\n",
       "        -0.20417899,  0.737419  ,  0.29582083,  0.737419  , -0.3041792 ,\n",
       "         0.737419  ,  0.39582103,  0.737419  ],\n",
       "       [ 0.00546694, -0.00443459, -0.24316639,  0.04445672, -0.04316628,\n",
       "         0.24445683, -0.24316639, -0.05554318,  0.05683362,  0.24445683,\n",
       "        -0.24316639,  0.14445662, -0.14316648,  0.24445683, -0.24316639,\n",
       "        -0.15554339,  0.15683353,  0.24445683],\n",
       "       [ 0.01151991, -0.01554318,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.01151931, -0.01554346,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0, dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(obs == - 100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2810,  0.1193,  0.0012,  0.3992, -0.0988,  0.3992,  0.1012,  0.3992,\n",
       "         -0.1988,  0.3992,  0.2012,  0.3992, -0.2988,  0.3992,  0.3012,  0.3992,\n",
       "         -0.3988,  0.3992],\n",
       "        [ 0.7567,  0.3899, -0.0042,  0.7374,  0.0958,  0.7374, -0.1042,  0.7374,\n",
       "          0.1958,  0.7374, -0.2042,  0.7374,  0.2958,  0.7374, -0.3042,  0.7374,\n",
       "          0.3958,  0.7374],\n",
       "        [ 0.0055, -0.0044, -0.2432,  0.0445, -0.0432,  0.2445, -0.2432, -0.0555,\n",
       "          0.0568,  0.2445, -0.2432,  0.1445, -0.1432,  0.2445, -0.2432, -0.1555,\n",
       "          0.1568,  0.2445],\n",
       "        [ 0.0115, -0.0155,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0115, -0.0155,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0, -1].get((\"agents\", \"observation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out[0, -1].get((\"agents\", \"observation\")) == -100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
