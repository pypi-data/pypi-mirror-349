# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from .raw_client import AsyncRawEvaluationSetClient, RawEvaluationSetClient
from .types.evaluation_set_create_response import EvaluationSetCreateResponse

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class EvaluationSetClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawEvaluationSetClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawEvaluationSetClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawEvaluationSetClient
        """
        return self._raw_client

    def create(
        self, *, name: str, description: str, processor_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluationSetCreateResponse:
        """
        Evaluation sets are collections of files and expected outputs that are used to evaluate the performance of a given processor in Extend. This endpoint will create a new evaluation set in Extend, which items can be added to using the [Create Evaluation Set Item](https://docs.extend.ai/2025-04-21/developers/api-reference/evaluation-set-endpoints/create-evaluation-set-item) endpoint.

        Note: it is not necessary to create an evaluation set via API. You can also create an evaluation set via the Extend dashboard and take the ID from there.

        Parameters
        ----------
        name : str
            The name of the evaluation set.

            Example: `"Invoice Processing Test Set"`

        description : str
            A description of what this evaluation set is used for.

            Example: `"Q4 2023 vendor invoices"`

        processor_id : str
            The ID of the processor to create an evaluation set for. Evaluation sets can in theory be run against any processor, but it is required to associate the evaluation set with a primary processor.

            Example: `"dp_Xj8mK2pL9nR4vT7qY5wZ"`

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationSetCreateResponse
            Successfully created evaluation set

        Examples
        --------
        from extend_ai import Extend
        client = Extend(token="YOUR_TOKEN", )
        client.evaluation_set.create(name='My Evaluation Set', description='My Evaluation Set Description', processor_id='processor_id_here', )
        """
        _response = self._raw_client.create(
            name=name, description=description, processor_id=processor_id, request_options=request_options
        )
        return _response.data


class AsyncEvaluationSetClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawEvaluationSetClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawEvaluationSetClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawEvaluationSetClient
        """
        return self._raw_client

    async def create(
        self, *, name: str, description: str, processor_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluationSetCreateResponse:
        """
        Evaluation sets are collections of files and expected outputs that are used to evaluate the performance of a given processor in Extend. This endpoint will create a new evaluation set in Extend, which items can be added to using the [Create Evaluation Set Item](https://docs.extend.ai/2025-04-21/developers/api-reference/evaluation-set-endpoints/create-evaluation-set-item) endpoint.

        Note: it is not necessary to create an evaluation set via API. You can also create an evaluation set via the Extend dashboard and take the ID from there.

        Parameters
        ----------
        name : str
            The name of the evaluation set.

            Example: `"Invoice Processing Test Set"`

        description : str
            A description of what this evaluation set is used for.

            Example: `"Q4 2023 vendor invoices"`

        processor_id : str
            The ID of the processor to create an evaluation set for. Evaluation sets can in theory be run against any processor, but it is required to associate the evaluation set with a primary processor.

            Example: `"dp_Xj8mK2pL9nR4vT7qY5wZ"`

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationSetCreateResponse
            Successfully created evaluation set

        Examples
        --------
        from extend_ai import AsyncExtend
        import asyncio
        client = AsyncExtend(token="YOUR_TOKEN", )
        async def main() -> None:
            await client.evaluation_set.create(name='My Evaluation Set', description='My Evaluation Set Description', processor_id='processor_id_here', )
        asyncio.run(main())
        """
        _response = await self._raw_client.create(
            name=name, description=description, processor_id=processor_id, request_options=request_options
        )
        return _response.data
