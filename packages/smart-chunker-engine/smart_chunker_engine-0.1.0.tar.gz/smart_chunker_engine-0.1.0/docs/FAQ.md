# Smart Chunker Engine: FAQ

## Общие вопросы / General Questions

**Q: Какие языки поддерживаются?**
A: Русский (spaCy ru_core_news_md), английский (en_core_web_sm), другие — при наличии spaCy-модели и SBERT.

**Q: Какие зависимости нужны?**
A: `chunk_metadata_adapter>=1.3.0`, `sentence-transformers`, `hdbscan`, `scikit-learn`, `spacy`, нужные spaCy-модели.

**Q: Какой минимальный размер текста?**
A: Любой, но для meaningful-результата желательно > 200 символов.

**Q: Какой формат результата?**
A: Список объектов SemanticChunk (или FlatSemanticChunk для экспорта).

**Q: Как настроить параметры пайплайна?**
A: Через config-словарь при создании SmartChunkerPipeline (см. COMPONENTS.md).

**Q: Как экспортировать результат?**
A: Через функцию `export_chunks` (см. Exporter).

**Q: Как проверить качество разбиения?**
A: Используйте скрипт `scripts/evaluate_boundaries.py` (F1, noise, CV).

**Q: Что делать, если мало чанков или пустой результат?**
A: Проверьте параметры split (chunk_size), убедитесь, что текст не слишком короткий.

**Q: Как ускорить обработку?**
A: Используйте batch-обработку, уменьшайте размер моделей, отключайте ненужные этапы.

**Q: Как добавить поддержку нового языка?**
A: Установите нужную spaCy-модель и SBERT, настройте config.

**Q: Как интегрировать в свой проект?**
A: Импортируйте SmartChunkerPipeline, передайте текст и config, экспортируйте результат.

**Q: Как отлаживать пайплайн?**
A: Включите логирование, проверяйте промежуточные этапы (см. pipeline.py), используйте тесты из tests/.

**Q: Что делать при ошибках HDBSCAN?**
A: Проверьте min_cluster, для малых текстов используйте min_cluster=2 или меньше.

**Q: Какой формат экспорта поддерживается?**
A: JSON (SemanticChunk/Flat), CSV/Parquet (только FlatSemanticChunk).

**Q: Какой максимальный размер текста?**
A: Ограничен памятью и производительностью, для больших файлов используйте батчи. 