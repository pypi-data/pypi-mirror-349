# Smart Chunker Engine: ТЗ (часть 1 из N)

**Официальный репозиторий:** [git@github.com:maverikod/vvz-smart-chunker-engine.git](git@github.com:maverikod/vvz-smart-chunker-engine.git)

> **Внимание!** Все операции с метаданными чанков (создание, хранение, экспорт, сериализация, статусы, метрики) должны выполняться исключительно через API и модели пакета [chunk_metadata_adapter](https://pypi.org/project/chunk-metadata-adapter/) (версии >=1.3.0). Форматы, сериализация, экспорт и валидация должны соответствовать [docs/implementation_plan.md](implementation_plan.md) и [docs/metadata_adapter_patch_spec.md](metadata_adapter_patch_spec.md).

## 1. Краткая цель проекта

Создать модуль **Full‑Stack Chunker**, который автоматически превращает «грязный» текст в структурированную коллекцию `SemanticChunk` / `FlatSemanticChunk` (пакет `chunk‑metadata‑adapter`), пригодную для RAG‑поиска, ML‑обработки и архивации.

### KPI

| Метрика                                | Цель                        |
| -------------------------------------- | --------------------------- |
| **F1** границ (по размеченной выборке) | ≥ 0 .90                     |
| Noise‑chunks                           | ≤ 3 %                       |
| Coef. Variation длины                  | ≤ 30 %                      |
| ΔScore итеративного улучшения          | ≤ 1 % за последнюю итерацию |

---

## 2. Обзор алгоритмических уровней

> Каждый уровень может быть включён/выключен по конфигурации; данные передаются после валидации.

| №  | Уровень                | Ключевой файл/модуль                       | Назначение                                |
| -- | ---------------------- | ------------------------------------------ | ----------------------------------------- |
| 0  | **Pre‑clean**          | `pre_normalize.py`                         | NFC, контрольные символы, двойные пробелы |
| 1  | **Fast Split**         | `initial_split.py`                         | fixed/hybrid нарезка (≈500 симв.)         |
| 2  | **Semantic Window**    | `boundary_segmenter.py`                    | SBERT + окно 20/10, порог Δ 0.15          |
| 3  | **Stats Gate**         | `stats_gate.py`                            | решает, включать ли TF‑IDF слой           |
| 4  | **TF‑IDF + Weights**   | `tfidf_layer.py`                           | частотный профиль + веса слов             |
| 5  | **Triple Cluster**     | `triple_extractor.py`, `triple_cluster.py` | POS‑тройки → темы, веса                   |
| 6  | **Metablock Split**    | `metablock_segmenter.py`                   | 3‑векторная (N/A/V) семантика             |
| 7  | **Iterative Refine**   | `iterative_refine.py`                      | MERGE/SPLIT по Score                      |
| 8  | **Chunk Metadata**     | `metadata_builder.py`                      | SemanticChunk + metrics                   |
| 9  | **Lifecycle Validate** | `lifecycle_validator.py`                   | RAW→RELIABLE, noise‑mark                  |
| 10 | **Index & Export**     | `exporter.py`                              | FlatChunk → vector DB / JSON              |

---

## 3. Ключевые алгоритмы этапов 2–7 (кратко)

### 2. Semantic Window

* **Вход:** токены (N,V,A) после POS‑фильтра.
* `window_size = 20`, `step = 10` → SBERT‑вектор.
* Граница, если cosine‑дист соседних > `thr` (начальное 0.15).

### 3. Stats Gate

* Считаем:

  * σ²<sub>TF</sub>, Entropy, Gini.
  * Если ≥ 2 метрик выполняют порог (`0.15 / 8 bit / 0.25`) → включаем TF‑IDF.

### 4. TF‑IDF + Weights

* Топ‑1000 лемм корпуса.
* Вес слова = TF‑IDF × weight(token) (см. уровень 5).

### 5. Triple Cluster

* Извлекаем тройки 〈N A V〉 (`spaCy ru_core_news_md`).
* SBERT → HDBSCAN (min\_cluster=5).
* `weight(token) = 1 + ln(1+size(cluster))`.

### 6. Metablock Split

* Для каждого чанка строим три TopicCore‑вектора.
* Граница, если любая ось Δ > 0.25.

### 7. Iterative Refine

* Scoring: `Score=Σ(cohesion – λ·boundary)` (λ=0.4).
* Операции MERGE / SPLIT — greedy; стоп, если прирост < ε (0.01).

---

## 4. Структура конфигурации (YAML)

```yaml
window_size: 20
step: 10
threshold_semantic: 0.15
stats_gate:
  var_thr: 0.15
  ent_thr: 8.0
  gini_thr: 0.25
triple_cluster:
  min_cluster: 5
merge_split:
  lambda: 0.4
  theta_high: 0.75
  theta_low: 0.35
  epsilon: 0.01
lifecycle:
  min_quality: 0.6   # coverage
resources:
  peak_ram_limit_mb: 1024
```

---

> **См. также:**
> - [docs/implementation_plan.md](implementation_plan.md) — общий план, стандарты интеграции, требования к chunk_metadata_adapter
> - [docs/metadata_adapter_patch_spec.md](metadata_adapter_patch_spec.md) — спецификация расширения и патча для адаптера

*(Следующая часть: детали файлов, API‑контракты, формат отчётов)*
