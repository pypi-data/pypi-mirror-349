{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building a New Dataset Bank for reLAISS\n",
        "\n",
        "This notebook explains how to create a new dataset bank for reLAISS using your own data. The process involves:\n",
        "\n",
        "1. Preparing your data in the required format\n",
        "2. Building the dataset bank with built-in preprocessing\n",
        "3. Creating the ANNOY index for fast similarity search\n",
        "4. Testing your new bank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preparation\n",
        "\n",
        "Your data should be organized into two CSV files:\n",
        "\n",
        "1. Lightcurve data with columns:\n",
        "   - ztf_object_id: ZTF ID of the transient\n",
        "   - ant_mjd: Modified Julian Date of observations\n",
        "   - ant_passband: Filter (g, r, i, z)\n",
        "   - ant_mag: Magnitude\n",
        "   - ant_magerr: Magnitude error\n",
        "\n",
        "2. Host galaxy data with columns:\n",
        "   - ztf_object_id: ZTF ID of the transient\n",
        "   - ra, dec: Host galaxy coordinates\n",
        "   - gKronMag, rKronMag, iKronMag, zKronMag: Host magnitudes\n",
        "   - gKronMagErr, rKronMagErr, iKronMagErr, zKronMagErr: Magnitude errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from relaiss import build_dataset_bank\n",
        "\n",
        "# Load your data\n",
        "lc_df = pd.read_csv('path/to/your/lightcurves.csv')\n",
        "host_df = pd.read_csv('path/to/your/hosts.csv')\n",
        "\n",
        "# Merge lightcurve and host data\n",
        "raw_df_bank = pd.merge(lc_df, host_df, on='ztf_object_id')\n",
        "print(f\"Loaded {len(raw_df_bank)} transients\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Building the Dataset Bank\n",
        "\n",
        "The `build_dataset_bank` function performs several preprocessing steps:\n",
        "\n",
        "1. **Missing Value Handling**:\n",
        "   - Replaces infinite values and -999 with NaN\n",
        "   - Uses KNN imputation for missing values\n",
        "   - Drops rows with NaN values after imputation\n",
        "\n",
        "2. **Dust Correction**:\n",
        "   - Uses SFD dust maps to correct host galaxy magnitudes\n",
        "   - Creates dust-corrected magnitude columns\n",
        "\n",
        "3. **Feature Engineering**:\n",
        "   - Creates color indices (g-r, r-i, i-z)\n",
        "   - Calculates color uncertainties\n",
        "   - Adds additional features for similarity search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the dataset bank\n",
        "bank_df = build_dataset_bank(\n",
        "    raw_df_bank=raw_df_bank,\n",
        "    path_to_sfd_folder='./sfddata-master',  # Path to SFD dust maps\n",
        "    building_entire_df_bank=True  # Set to True when building a new bank\n",
        ")\n",
        "\n",
        "# Save the processed bank\n",
        "output_path = './my_dataset_bank.csv'\n",
        "bank_df.to_csv(output_path, index=False)\n",
        "print(f\"Dataset bank created at: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Creating the ANNOY Index\n",
        "\n",
        "After building the dataset bank, you need to create an ANNOY index for fast similarity search. This is done automatically when you initialize the ReLAISS client with your new bank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from relaiss import ReLAISS\n",
        "\n",
        "# Initialize ReLAISS with your new bank\n",
        "client = ReLAISS()\n",
        "client.load_reference(\n",
        "    bank_path=output_path,\n",
        "    path_to_sfd_folder='./sfddata-master'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Testing Your Bank\n",
        "\n",
        "Let's test your new dataset bank by finding neighbors for a known transient:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find neighbors for a test transient\n",
        "test_ztf_id = 'ZTF21aaublej'  # Replace with a ZTF ID from your bank\n",
        "neighbors = client.find_neighbors(\n",
        "    ztf_object_id=test_ztf_id,\n",
        "    n=5,  # Number of neighbors to find\n",
        "    plot=True  # Generate diagnostic plots\n",
        ")\n",
        "\n",
        "print(\"\\nFound neighbors:\")\n",
        "print(neighbors[['neighbor_num', 'ztf_link', 'dist', 'spec_cls', 'z']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "You have now:\n",
        "1. Prepared your data in the required format\n",
        "2. Built a dataset bank with built-in preprocessing\n",
        "3. Created an ANNOY index for fast similarity search\n",
        "4. Tested your bank by finding similar transients\n",
        "\n",
        "Your new dataset bank is ready to use with reLAISS!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
