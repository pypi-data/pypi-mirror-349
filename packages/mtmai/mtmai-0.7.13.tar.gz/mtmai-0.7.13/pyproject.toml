[project]
name = "mtmai"
version = "0.7.13"
dependencies = [
    "pydantic-settings",
    "litellm>=1.69.3",
    "beautifulsoup4>=4.13.4",
    "pandas>=2.2.2",
    "python-dotenv>=1.0.1",
    "tiktoken>=0.7",
    "tqdm>=4.66.4",
    "minify-html>=0.15.0",
    "free-proxy>=1.1.1",
    # "playwright>=1.51.0",
    # "Crawl4AI>=0.5.0.post8",
    "rebrowser-playwright>=1.49.1",
    "undetected-playwright>=0.3.0",
    # "qdrant-client>=1.11.3",
    # "fastembed>=0.3.6",
    "semchunk>=2.2.0",
    "transformers>=4.44.2",
    "googlesearch-python>=1.2.5",
    "simpleeval>=1.0.0",
    "async_timeout>=4.0.3",
    "scrapegraph-py>=1.7.0",
    "fastapi>=0.115.7",
    # "scrapegraphai>=1.33.3",
    # "crewai>=0.95.0",
    "structlog>=24.4.0",
    "langgraph>=0.2.63",
    "langgraph-checkpoint-postgres>=2.0.13",
    "lazify>=0.4.0",
    # docling 这个库,依赖项很庞大.其中有torch接近1G体积
    # "docling>=2.14.0",
    "orjson>=3.10.1",
    "sqlmodel>=0.0.22",
    "nanoid>=2.0.0",
    # "opentelemetry-instrumentation>=0.49b0",
    # "opentelemetry-distro>=0.49b0",
    # "opentelemetry-exporter-otlp>=1.28.0",
    # "opentelemetry-exporter-otlp-proto-http>=1.28.0",
    "python-dotenv>=1.0.0",
    # "protobuf>=5.29.1",
    # "grpcio-tools>=1.68.1",
    "pyyaml>=6.0.1",
    "aiostream>=0.5.2",
    "nest-asyncio>=1.6.0",
    "aiohttp>=3.10.5",
    "aiohttp-retry>=2.8.3",
    "tenacity>=8.4.1",
    "cel-python>=0.1.5",
    "python-dateutil>=2.9.0.post0",
    "loguru>=0.7.3",
    "browser-use>=0.1.47",
    "pgvector>=0.3.6",
    "sqlalchemy>=2.0.37",
    "psycopg2-binary>=2.9.10",
    # "mem0ai>=0.1.44",
    "openai>=1.59.7",
    "exa-py>=1.7.2",
    # "newspaper4k>=0.9.3.1",
    "lxml-html-clean>=0.4.1",
    "huggingface-hub>=0.27.1",
    # "autogen-core @file:///home/user/workspace/autogen/python/packages/autogen-core",
    # "autogen-agentchat @file:///home/user/workspace/autogen/python/packages/autogen-agentchat",
    # "autogen-ext @file:///home/user/workspace/autogen/python/packages/autogen-ext",
    # "google-adk @file:///home/user/workspace/adk-python",
    # 开发板执行: pip install git+https://github.com/google/adk-python.git@main
    "google-adk>=0.5.0",
    "email-validator>=2.2.0",
    "passlib>=1.7.4",
    "json-repair>=0.35.0",
    "typer>=0.13.1",
    "pydantic>=2.10.5",
    "pyOpenSSL>=24.3.0",
    "alembic>=1.14.1",
    "slugify>=0.0.1",
    "yfinance>=0.2.52",
    "mcp-server-fetch>=2025.1.17",
    "connecpy>=1.4.2",
    "opentelemetry-instrumentation-openai>=0.38.11",
    "opentelemetry-exporter-otlp>=1.30.0",
    "opentelemetry-exporter-otlp-proto-http>=1.30.0",
    "markdownify>=1.1.0",
    "langchain-core>=0.3.49",
    "langchain-openai>=0.3.1",
    "langchain-anthropic>=0.3.3",
    "langchain-ollama>=0.2.2",
    "langchain>=0.3.18",
    "langchain-community>=0.3.19",
    "langchain-ollama>=0.1.3",
    "langchain-nvidia-ai-endpoints>=0.3.9",
    "quantstats",
    "json-schema-to-pydantic>=0.2.2",
    "smolagents[telemetry,litellm]>=1.16.1",
    "anthropic>=0.49.0",
    "html2text>=2024.2.26",
    "azure-core>=1.32.0",
    "azure-identity>=1.21.0",
    "pycryptodomex>=3.22.0",
    "pyotp>=2.9.0",
    "docker>=7.1.0",
    "asyncio-atexit>=1.0.1",
    "chromadb>=1.0.4",
    "markitdown>=0.1.1",
    "selenium>=4.31.0",
    "diff-match-patch>=20241021",
    "absl-py>=2.2.2",
    "pdfplumber>=0.11.6",
    # "langchain-google-genai>=2.1.2",
    # "playwright-stealth>=1.0.6",
    "colorama>=0.4.6",
    "xxhash>=3.5.0",
    # crawl4ai ========================================
    "aiosqlite~=0.20",
    "lxml~=5.3",
    "numpy>=1.26.0,<3",
    "xxhash~=3.4",
    "rank-bm25~=0.2",
    "colorama~=0.4",
    "snowballstemmer~=2.2",
    "pydantic>=2.10",
    "pyOpenSSL>=24.3.0",
    "psutil>=6.1.1",
    "nltk>=3.9.1",
    "playwright",
    "rich>=13.9.4",
    "cssselect>=1.2.0",
    "httpx>=0.27.2",
    "fake-useragent>=2.0.3",
    "click>=8.1.7",
    "pyperclip>=1.8.2",
    "faust-cchardet>=2.1.19",
    "aiohttp>=3.11.11",
    "humanize>=4.10.0",
    "helium>=5.1.1",
    "pathvalidate>=3.2.3",
    "serpapi>=0.1.5",
    "google-search-results>=2.4.2",
    "mammoth>=1.9.0",
    "youtube-transcript-api>=1.0.3",
    "speechrecognition>=3.14.2",
    "python-pptx>=1.0.2",
    "pypdf>=5.4.0",
    "puremagic>=1.28",
    "xlrd>=2.0.1",
    "pdfminer-six>=20250327",
    "fastapi-mcp>=0.3.0",
    "playwright-stealth>=1.0.6",
    "tiktokapi>=7.1.0",
    "py-mini-racer>=0.6.0",
    "browser-cookie3>=0.20.1",
    "websockets-proxy>=0.1.3",
    "jsonpath-ng>=1.7.0",
    "m3u8>=6.0.0",
    "edge-tts>=6.1.19",
    "redis>=6.0.0",
    "boto3>=1.38",
    "fastmcp>=2.2.7",
    "g4f[webview]>=0.5.2.1",
    "moviepy>=2.0.0.dev2",
    "faster-whisper~=1.0.1",
    "pysrt>=1.1.2",
    "opencv-python~=4.10.0.84",
    "pydub>=0.25.1",
    "asyncpg>=0.30.0",
    "psycopg-binary>=3.2.7",
    "langfuse>=2.60.4",
    "opentelemetry-sdk>=1.32.0",
    "openinference-instrumentation-smolagents>=0.1.8",
    "hatchet-sdk>=1.10.1",
    "toolbox-core>=0.1.0",
    "toolbox-langchain>=0.1.0",
    "pytubefix>=8.13.1",                               # youtube下载器(同时能下载字幕)
    "ffmpeg-python>=0.2.0",                            # 视频音频处理
    "lark>=0.12.0",
]

description = "A web scraping library based on LangChain which uses LLM and direct graph logic to create scraping pipelines."
authors = [{ name = "Marco Vinciguerra", email = "mvincig11@gmail.com" }]
license = "MIT"
readme = "README.md"
keywords = ["scrapegraph", "llm"]
classifiers = [
    "Intended Audience :: Developers",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Programming Language :: Python :: 3",
    "Operating System :: OS Independent",
]
requires-python = ">=3.12,<4.0"


[project.scripts]
mtmai = "mtmai.main:app"
# [project.optional-dependencies]
#     burr = ["burr[start]==0.22.1"]
# docs = ["sphinx==6.0", "furo==2024.5.6"]

# [project.optional-dependencies]
[dependency-groups]
dev = [
    "aiofiles>=0.8.0",
    "grpcio>=1.70.0",
    "aiofiles>=0.8.0",
    "tokencost~=0.1.16",
    "build~=1.2.2",
    "pytest~=8.3.3",
    "pytest-asyncio~=0.24.0",
    "matplotlib>=3.10.0",
    "gradio>=5.12.0",
    "prometheus-client>=0.21.1",
    "pytest-watcher>=0.4.3",

    # other
    # "prefect>=3.1.13",
    # "opentelemetry-instrumentation-openai>=0.33.9",
    # "markitdown",

]

# Group 1: Other Language Models
other-language-models = [
    "langchain-google-vertexai>=1.0.7",
    "langchain-fireworks>=0.1.3",
    "langchain-groq>=0.1.3",
    "langchain-anthropic>=0.1.11",
    "langchain-huggingface>=0.0.3",
    # "langchain-nvidia-ai-endpoints>=0.1.6",
    "langchain_together>=0.2.0",

]

# Group 2: More Semantic Options
more-semantic-options = ["graphviz>=0.20.3"]

# Group 3: More Browser Options
more-browser-options = ["browserbase>=0.3.0"]

# Group 4: Surya Library
screenshot_scraper = [
    # "surya-ocr>=0.5.0",
    "matplotlib>=3.7.2",
    "ipywidgets>=8.1.0",
    # "pillow>=10.4.0",
]

[build-system]
requires = ["hatchling>=1.0.0", "hatch-vcs"]
build-backend = "hatchling.build"

[tool.hatch.build]
packages = ["mtmai"]
exclude = ["tests/**", ".vol/**", "__pycache__/**"]

[tool.hatch.version]
source = "vcs"

[tool.hatch.build.hooks.vcs]
version-file = "mtmai/_version.py"

[tool.hatch.build.targets.wheel]
packages = ["mtmai"]

[tool.hatch.build.targets.sdist]
include = ["mtmai", "pyproject.toml", "README.md", "LICENSE"]
packages = ["mtmai"]

[tool.hatch.metadata]
allow-direct-references = true


# [dependency-groups]
# dev = [
#     "burr[start]==0.22.1",
#     "sphinx==6.0",
#     "furo==2024.5.6",
#     "tokencost>=0.1.16",
#     "hatch>=1.13.0",
#     "build>=1.2.2",
#     "pytest>=8.3.3",
#     "pytest-asyncio>=0.24.0"
# ]

# [tool.uv]
# dev-dependencies = [
#     "poethepoet>=0.31.1",
#     # "pytest==8.0.0",
#     "pytest-mock==3.14.0",
#     "pylint>=3.2.5",
# ]


[tool.uv.sources]
quantstats = { git = "https://github.com/PowerInsight/quantstats.git" }
