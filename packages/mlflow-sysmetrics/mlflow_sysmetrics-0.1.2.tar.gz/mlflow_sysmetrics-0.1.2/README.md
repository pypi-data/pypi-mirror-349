# mlflow-sysmetrics

ğŸ§  A lightweight [MLflow Run Context Provider](https://mlflow.org/docs/latest/tracking.html#context-providers) that automatically logs system-level metrics (CPU, memory, disk, GPU, OS) as run tags.

> âœ… Cross-platform Â· ğŸ”Œ Plugin-ready Â· ğŸ§ª Tested Â· âš™ï¸ Minimal dependencies

---

## ğŸ“¦ What it does

This plugin automatically adds system environment metadata to each MLflow run. It enables lightweight observability for experiment tracking â€” useful in both local development and remote execution contexts.

### âœ… Captured Tags

| Tag Key            | Description                               |
| ------------------ | ----------------------------------------- |
| `sys.cpu`          | CPU model or architecture                 |
| `sys.cpu_cores`    | Logical CPU core count                    |
| `sys.memory_gb`    | Total system memory (GB)                  |
| `sys.disk_free_gb` | Free disk space in current directory (GB) |
| `sys.platform`     | OS and kernel version                     |
| `sys.gpu`          | GPU name via `nvidia-smi` or "None"       |
| `sysmetrics.error` | Captures any exception during tagging     |

---

## ğŸš€ Installation

```bash
poetry add mlflow-sysmetrics
```

> Requires: Python â‰¥ 3.9 Â· `mlflow` â‰¥ 2.0 Â· `psutil` (automatically included)

---

## ğŸ› ï¸ Usage

Set the environment variable to activate the plugin:

```bash
export MLFLOW_RUN_CONTEXT_PROVIDER=sysmetrics
```

Then run any MLflow experiment:

```python
import mlflow

with mlflow.start_run():
    mlflow.log_param("foo", "bar")
    # Plugin will automatically add sys.* tags
```

---

## ğŸ§ª Testing

Run both unit and integration tests:

```bash
poetry run pytest -m unit
poetry run pytest -m integration
```

To manually verify plugin behavior:

```bash
export MLFLOW_RUN_CONTEXT_PROVIDER=sysmetrics
poetry run python scripts/debug_run.py
```

### ğŸ“· Example: Debug Script Output

You can verify system metrics manually with the debug script. Below is a sample output:

![Example terminal output of sysmetrics plugin](assets/debug_run.png)

---

## ğŸ” Project Structure

```text
mlflow-sysmetrics/
â”œâ”€â”€ src/mlflow_sysmetrics/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py
â”‚   â””â”€â”€ system_context.py         # Plugin implementation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                     # Logic-only tests
â”‚   â””â”€â”€ integration/              # MLflow integration tests
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ debug_run.py              # Manual testing script
â”œâ”€â”€ assets/                       # Image and media assets
â”‚   â””â”€â”€ debug_run.png             # Screenshot of debug script
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

## ğŸ“© Plugin Registration

This plugin is exposed to MLflow via entry points:

```toml
[tool.poetry.plugins."mlflow.run_context_provider"]
sysmetrics = "mlflow_sysmetrics:SysMetricsRunContextProvider"
```

---

## ğŸ¤ Contributing

Pull requests, bug reports, and suggestions are welcome!

1. Fork the repo
2. Create a virtual environment: `poetry install`
3. Write or update tests
4. Run tests with `poetry run pytest`
5. Submit your PR ğŸš€

---

## ğŸ“„ License

Apache License 2.0. See [`LICENSE`](./LICENSE) for full terms.

---

## ğŸ’¬ Questions?

Feel free to open an issue or reach out via GitHub Discussions.